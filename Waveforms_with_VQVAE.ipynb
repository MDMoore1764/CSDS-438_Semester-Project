{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wavfile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's design the VQ VAE layers, since this is not a part of Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VectorQuantizer(keras.layers.Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "\n",
    "        # The `beta` parameter is best kept between [0.25, 2] as per the paper.\n",
    "        self.beta = beta\n",
    "\n",
    "        # Initialize the embeddings which we will quantize.\n",
    "        w_init = tf.random_uniform_initializer()\n",
    "        self.embeddings = tf.Variable(\n",
    "            initial_value=w_init(\n",
    "                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # Calculate the input shape of the inputs and\n",
    "        # then flatten the inputs keeping `embedding_dim` intact.\n",
    "        input_shape = tf.shape(x)\n",
    "        flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
    "\n",
    "        # Quantization.\n",
    "        encoding_indices = self.get_code_indices(flattened)\n",
    "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
    "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
    "\n",
    "        # Reshape the quantized values back to the original input shape\n",
    "        quantized = tf.reshape(quantized, input_shape)\n",
    "\n",
    "        # Calculate vector quantization loss and add that to the layer. You can learn more\n",
    "        # about adding losses to different layers here:\n",
    "        # https://keras.io/guides/making_new_layers_and_models_via_subclassing/. Check\n",
    "        # the original paper to get a handle on the formulation of the loss function.\n",
    "        commitment_loss = tf.reduce_mean((tf.stop_gradient(quantized) - x) ** 2)\n",
    "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
    "        self.add_loss(self.beta * commitment_loss + codebook_loss)\n",
    "\n",
    "        # Straight-through estimator.\n",
    "        quantized = x + tf.stop_gradient(quantized - x)\n",
    "        return quantized\n",
    "\n",
    "    def get_code_indices(self, flattened_inputs):\n",
    "        # Calculate L2-normalized distance between the inputs and the codes.\n",
    "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
    "        distances = (\n",
    "            tf.reduce_sum(flattened_inputs**2, axis=1, keepdims=True)\n",
    "            + tf.reduce_sum(self.embeddings**2, axis=0)\n",
    "            - 2 * similarity\n",
    "        )\n",
    "\n",
    "        # Derive the indices for minimum distances.\n",
    "        encoding_indices = tf.argmin(distances, axis=1)\n",
    "        return encoding_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the VQ VAE is defined, we need to define our encoder and decoder. This can be any model for encoding and decoding. OpenAI's JukeBox project uses noncausal 1-D dilated convolutions, interleaved with downsampling and upsampling 1-D convolutions. So let's use this approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(input_shape, conv_filters, latent_dim):\n",
    "    encoder_inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = keras.layers.Conv1D(conv_filters, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
    "        encoder_inputs\n",
    "    )\n",
    "    \n",
    "    x = keras.layers.Conv1D(2 * conv_filters, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    \n",
    "    encoder_outputs = keras.layers.Conv1D(latent_dim, 1, padding=\"same\")(x)\n",
    "    return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
    "\n",
    "\n",
    "def get_decoder(input_shape, conv_filters, latent_dim):\n",
    "    latent_inputs = keras.Input(shape=get_encoder(input_shape, conv_filters, latent_dim).output.shape[1:])\n",
    "    \n",
    "    x = keras.layers.Conv1DTranspose(\n",
    "        2 * conv_filters, 3, activation=\"relu\", strides=2, padding=\"same\"\n",
    "    )(latent_inputs)\n",
    "    \n",
    "    x = keras.layers.Conv1DTranspose(\n",
    "        conv_filters, 3, activation=\"relu\", strides=2, padding=\"same\"\n",
    "    )(x)\n",
    "    \n",
    "    decoder_outputs = keras.layers.Conv1DTranspose(1, 3, padding=\"same\")(x)\n",
    "    return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "def get_vqvae(input_shape, num_embeddings, conv_filters, latent_dim):\n",
    "    vq_layer = VectorQuantizer(num_embeddings, latent_dim, name=\"vector_quantizer\")\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    encoder = get_encoder(input_shape, conv_filters, latent_dim)\n",
    "    decoder = get_decoder(input_shape, conv_filters, latent_dim)\n",
    "    \n",
    "    encoder_outputs = encoder(inputs)\n",
    "    quantized_latents = vq_layer(encoder_outputs)\n",
    "    reconstructions = decoder(quantized_latents)\n",
    "    return keras.Model(inputs, reconstructions, name=\"vq_vae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load from raw wav data and test our network's ability to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8820, 65535)\n",
      "8820\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "embedding_size = 2 ** 16 - 1\n",
    "\n",
    "def load_song_file(song_file: str):\n",
    "    rate, song_data = wavfile.read(song_file)\n",
    "\n",
    "    mono_data = song_data\n",
    "\n",
    "    if song_data.shape[1] == 2:\n",
    "        mono_data = np.average(song_data, axis=1)\n",
    "        \n",
    "    audio = (mono_data / np.max(mono_data))\n",
    "    audio = (audio * embedding_size) - 2 ** 15\n",
    "    audio = audio.astype(np.int16)\n",
    "    return rate, audio\n",
    "        \n",
    "        \n",
    "def get_training_sequences(data, rate, chunk_duration):\n",
    "    chunk_size = int(rate * chunk_duration)\n",
    "    \n",
    "    Xs = []\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunk = data[i:i + chunk_size]\n",
    "        chunk = np.pad(chunk, (0, chunk_size - len(chunk)), mode='constant')\n",
    "        chunk = tf.one_hot(chunk, depth=embedding_size)\n",
    "        Xs.append(chunk)\n",
    "        # Ys.append(chunk[-1])\n",
    "        \n",
    "        \n",
    "    X = np.array(Xs)\n",
    "    # Y = np.array(Ys)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "\n",
    "sample_song = \"data/Wavs/tvari-tokyo-cafe-159065.wav\"\n",
    "rate, data = load_song_file(sample_song)\n",
    "\n",
    "test_duration = 10\n",
    "sequence_duration = 0.2\n",
    "set_samples = int(sequence_duration * rate)\n",
    "data = data[:set_samples * test_duration]\n",
    "\n",
    "\n",
    "X = get_training_sequences(data, rate, sequence_duration)\n",
    "\n",
    "print(X.shape)\n",
    "print(set_samples)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vq_vae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 8820, 65535)]     0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 2205, 32)          6299680   \n",
      "                                                                 \n",
      " vector_quantizer (VectorQu  (None, 2205, 32)          2097120   \n",
      " antizer)                                                        \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 8820, 1)           12481     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8409281 (32.08 MB)\n",
      "Trainable params: 8409281 (32.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_filters = 32\n",
    "latent_dim = 32\n",
    "n_batch = 32\n",
    "\n",
    "vaqae = get_vqvae((set_samples, embedding_size), embedding_size, conv_filters, latent_dim)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss = keras.losses.MeanSquaredError()\n",
    "\n",
    "vaqae.compile(optimizer=optimizer, loss=loss, metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "vaqae.summary()\n",
    "\n",
    "# epochs = 1\n",
    "# x_train = X[:n_train_size]\n",
    "# vaqae.fit(x_train, x_train, batch_size=n_batches, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VQVAETrainer(keras.models.Model):\n",
    "    def __init__(self, train_variance, input_shape, conv_filters = 32, latent_dim=32, num_embeddings=128, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.train_variance = train_variance\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        # self.input_shape = input_shape\n",
    "        # self.conv_filters = conv_filters\n",
    "\n",
    "        self.vqvae = get_vqvae(input_shape, self.num_embeddings, conv_filters, self.latent_dim)\n",
    "\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.vq_loss_tracker = keras.metrics.Mean(name=\"vq_loss\")\n",
    "        self.optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "        checkpoint = tf.train.Checkpoint(optimizer=self.optimizer, model=self.vqvae)\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(checkpoint, './checkpoints/Waveforms_with_VQVAE', checkpoint_name=\"checkpoint\", max_to_keep=5)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.vq_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Outputs from the VQ-VAE.\n",
    "            reconstructions = self.vqvae(x)\n",
    "\n",
    "            # Calculate the losses.\n",
    "            reconstruction_loss = (\n",
    "                tf.reduce_mean((x - reconstructions) ** 2) / self.train_variance\n",
    "            )\n",
    "            total_loss = reconstruction_loss + sum(self.vqvae.losses)\n",
    "\n",
    "        # Backpropagation.\n",
    "        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n",
    "\n",
    "        # Loss tracking.\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n",
    "\n",
    "        # Log results.\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"vqvae_loss\": self.vq_loss_tracker.result(),\n",
    "        }\n",
    "        \n",
    "        \n",
    "conv_filters = 32\n",
    "latent_dim = 32\n",
    "n_batch = 1\n",
    "input_shape = (set_samples, embedding_size)\n",
    "\n",
    "\n",
    "# x_train = X[:n_train_size * n_batch]\n",
    "\n",
    "# trainer = VQVAETrainer(1, input_shape, conv_filters, latent_dim, embedding_size)\n",
    "\n",
    "# for epoch in  tqdm(range(epochs), \"Epoch\"):\n",
    "#     for i in tqdm(range(0, x_train.shape[0], n_batch), \"Batch\"):\n",
    "        \n",
    "#         step_x = np.array(x_train[i:n_batch])\n",
    "#         result = trainer.train_step(step_x)\n",
    "        \n",
    "#     # Checkpoints\n",
    "#     trainer.checkpoint_manager.save()\n",
    "    \n",
    "    \n",
    "    \n",
    "def fit_vqvae(data, batch_size, epochs):\n",
    "    trainer = VQVAETrainer(0.2, input_shape, conv_filters, latent_dim, embedding_size)\n",
    "    \n",
    "    for _ in  range(epochs):\n",
    "        for i in tqdm(range(0, data.shape[0], batch_size), \"Batch\"):\n",
    "            step_x = data[i: i + batch_size]\n",
    "            result = trainer.train_step(step_x)\n",
    "            for key, value in result.items():\n",
    "                print(f\"{key}: {value}\", sep = \" | \", end=\"\")\n",
    "\n",
    "        # Checkpoints\n",
    "        trainer.checkpoint_manager.save()\n",
    "        \n",
    "        \n",
    "    return trainer.vqvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  33%|███▎      | 1/3 [00:06<00:12,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0005145255126990378reconstruction_loss: 9.880522702587768e-05vqvae_loss: 0.00041572030750103295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  67%|██████▋   | 2/3 [00:11<00:05,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0005372579907998443reconstruction_loss: 0.00013322987069841474vqvae_loss: 0.0004040281055495143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 3/3 [00:17<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0005027667502872646reconstruction_loss: 0.00011422794341342524vqvae_loss: 0.0003885387850459665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "n_train_size = 3\n",
    "\n",
    "x_train = X[:n_train_size * n_batch]   \n",
    "model = fit_vqvae(x_train, n_batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Nothing except the root object matched a checkpointed value. Typically this means that the checkpoint does not match the Python program. The following objects have no matching checkpointed value: [<tf.Variable 'conv1d_30/kernel:0' shape=(3, 65535, 32) dtype=float32, numpy=\narray([[[ 3.1859837e-03,  2.4147369e-03, -1.6694725e-03, ...,\n         -1.8291040e-03, -2.6177289e-04,  1.7357273e-03],\n        [-2.5135255e-03, -4.5673917e-03, -2.1778131e-03, ...,\n         -3.6310772e-03,  5.4083904e-03, -1.4033807e-03],\n        [-3.5876790e-03,  7.6853437e-04, -5.6006107e-04, ...,\n         -2.2224598e-03, -1.5791086e-03,  5.4973783e-03],\n        ...,\n        [ 2.3595206e-03,  3.8966136e-03,  1.4242004e-03, ...,\n          7.7969674e-04, -3.9009377e-05,  3.9720479e-03],\n        [-3.5629433e-03, -5.4414067e-03,  4.8809741e-03, ...,\n          4.4001173e-03, -2.8449520e-03,  5.4237749e-03],\n        [ 5.4534543e-03,  4.5976443e-03, -4.3144114e-03, ...,\n          4.9228929e-03, -2.7507984e-03,  3.8739070e-03]],\n\n       [[-5.1633692e-03, -3.7718844e-03, -1.3442561e-03, ...,\n         -4.6979450e-04,  4.6077194e-03,  4.4519287e-03],\n        [-3.7826675e-03,  1.6576871e-03, -2.5718918e-03, ...,\n          4.7918493e-03, -2.2136651e-03, -4.2763511e-03],\n        [-5.1356563e-03, -1.1466434e-03, -4.8627807e-03, ...,\n         -1.7672973e-03,  3.7822593e-04,  5.2022561e-03],\n        ...,\n        [-4.2552473e-03,  2.9366547e-03, -4.1953428e-03, ...,\n          3.6285780e-03, -5.3478023e-03, -2.0406761e-03],\n        [ 3.3119433e-03, -3.6730669e-03,  1.5852344e-03, ...,\n          5.4777376e-03, -5.5082953e-03, -5.0519528e-03],\n        [-4.1364776e-03, -5.4222108e-03,  1.6961582e-03, ...,\n          4.9377559e-04, -5.1352852e-03, -4.3449025e-03]],\n\n       [[-9.5041050e-04,  1.2265798e-03, -1.9765780e-03, ...,\n          5.2515129e-03,  4.1370820e-03,  4.5987722e-03],\n        [ 6.6309096e-04, -3.5401920e-03,  1.1831312e-03, ...,\n         -3.2820432e-03, -3.3968056e-03,  3.1397166e-03],\n        [-3.3389109e-03,  1.9180365e-03, -2.9727148e-03, ...,\n         -5.3149369e-03, -3.3569559e-03, -1.0492639e-03],\n        ...,\n        [ 4.5091109e-03, -2.0903607e-03, -1.6199972e-03, ...,\n          1.3179849e-03, -8.3639100e-04, -3.6963606e-03],\n        [ 2.5240779e-03, -1.0162778e-04,  1.3731290e-03, ...,\n         -2.7470719e-03, -5.3463685e-03, -1.8320605e-04],\n        [ 4.7342153e-03, -3.6527212e-03,  4.5936638e-03, ...,\n         -5.1843957e-03,  8.0442755e-04, -1.8358382e-03]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_17/kernel:0' shape=(3, 1, 32) dtype=float32, numpy=\narray([[[-0.08154388, -0.01174907,  0.113837  ,  0.03406376,\n         -0.17679563, -0.1865876 , -0.21403912, -0.05896947,\n          0.12011567,  0.15494111,  0.08926427, -0.15880921,\n         -0.14394802, -0.19183466,  0.16731048, -0.16774364,\n          0.06706849,  0.10767704,  0.21678862,  0.22105828,\n          0.19796467,  0.09410751, -0.15758783, -0.03965096,\n         -0.12124408, -0.03522627, -0.20542282, -0.11443803,\n         -0.04697616,  0.12317649, -0.24587242,  0.00504264]],\n\n       [[-0.07125717, -0.05961129,  0.23443967, -0.20154591,\n         -0.09992261,  0.24386913,  0.18912402,  0.1030758 ,\n         -0.08639428, -0.19838227,  0.23030192,  0.07771915,\n         -0.08384305,  0.11614558,  0.12786394,  0.01417083,\n          0.1395801 , -0.05985029, -0.16185945, -0.15315463,\n          0.01897496,  0.16857064, -0.04549119,  0.14801615,\n         -0.12777439, -0.14883512, -0.13611764, -0.17222449,\n         -0.08062865, -0.1225164 , -0.24166602, -0.10236356]],\n\n       [[ 0.06882024,  0.17553851,  0.16143638, -0.02033697,\n         -0.05426991, -0.12454659,  0.15727141,  0.1670284 ,\n         -0.01172918, -0.08040185, -0.20640142,  0.18147126,\n         -0.14146501,  0.10026082,  0.18389305, -0.00745168,\n          0.10735041,  0.24109039, -0.20862548, -0.00157049,\n          0.03616625, -0.20623426,  0.03829193,  0.11895201,\n          0.2397081 ,  0.01820338, -0.04466254,  0.15929642,\n          0.0692524 , -0.1493024 ,  0.01569095, -0.20330387]]],\n      dtype=float32)>, <tf.Variable 'conv1d_31/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\narray([[[ 0.0134176 ,  0.0315565 , -0.12363406, ..., -0.10226497,\n         -0.01555102,  0.06672172],\n        [-0.03083324, -0.08332602, -0.06957403, ..., -0.05285521,\n         -0.01849659,  0.00485657],\n        [ 0.04895036, -0.0934306 ,  0.01247899, ..., -0.06719256,\n          0.00969177,  0.1022892 ],\n        ...,\n        [-0.06584523,  0.02753694,  0.10897338, ...,  0.05134931,\n          0.06056477, -0.03066645],\n        [ 0.12302774, -0.12808466,  0.08843504, ...,  0.13798133,\n          0.07368718, -0.08908799],\n        [ 0.0549835 ,  0.05663067,  0.06186938, ...,  0.1141268 ,\n          0.06791912, -0.10422354]],\n\n       [[-0.09315658,  0.10344137,  0.06282596, ..., -0.0971553 ,\n         -0.06323699,  0.0111127 ],\n        [ 0.02285658,  0.09423524, -0.09941649, ...,  0.07447423,\n          0.0666094 ,  0.13799018],\n        [-0.09526642,  0.11759356,  0.08069433, ...,  0.0256554 ,\n          0.02175219, -0.07469719],\n        ...,\n        [-0.1075101 , -0.06870235,  0.0763894 , ...,  0.0734691 ,\n          0.10942778, -0.11182983],\n        [-0.07507181, -0.08195907,  0.03617947, ..., -0.05581746,\n         -0.0361846 ,  0.02509099],\n        [ 0.02645347, -0.06087837,  0.10308607, ..., -0.11828067,\n          0.11784258,  0.02180302]],\n\n       [[ 0.05438672,  0.12130535, -0.05720047, ...,  0.10046013,\n          0.12323436,  0.06498258],\n        [-0.07752909,  0.01212832, -0.08583842, ..., -0.08754234,\n         -0.03217937, -0.13251747],\n        [-0.14246655, -0.06036015,  0.04756463, ...,  0.13602024,\n          0.11706239,  0.11196637],\n        ...,\n        [-0.04782169,  0.00249688, -0.02427036, ..., -0.09003954,\n          0.00874738, -0.12035149],\n        [ 0.01497085, -0.13379312,  0.13513541, ..., -0.07636353,\n         -0.08510918,  0.03023708],\n        [-0.04170448, -0.03197953, -0.11718769, ...,  0.06908754,\n          0.07115327, -0.10701091]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_16/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\narray([[[ 0.10989046,  0.13917348, -0.07338534, ...,  0.03600191,\n         -0.06865896,  0.13270265],\n        [ 0.00683445,  0.03824528, -0.02396804, ...,  0.0871051 ,\n          0.07592838, -0.08140943],\n        [-0.0040115 ,  0.05761859,  0.06494844, ..., -0.12997048,\n         -0.09478013, -0.11157012],\n        ...,\n        [-0.13186727,  0.13046455, -0.09267844, ..., -0.13653176,\n         -0.12463537, -0.11212747],\n        [-0.07517102,  0.03225759, -0.11844795, ..., -0.11330314,\n         -0.13146423, -0.04276993],\n        [-0.05563015, -0.12825204, -0.1267446 , ..., -0.14147122,\n          0.02683689,  0.14150465]],\n\n       [[ 0.09893382, -0.05116513,  0.06521076, ...,  0.11298025,\n          0.08167055, -0.0201943 ],\n        [-0.13439348, -0.11682215,  0.08582625, ..., -0.05620635,\n         -0.13956149,  0.08771674],\n        [-0.03171603, -0.0502078 , -0.10745776, ..., -0.08051897,\n         -0.11233965, -0.07662851],\n        ...,\n        [-0.12143491, -0.03563544,  0.12245643, ..., -0.01109846,\n          0.14301443,  0.01297021],\n        [-0.12052335, -0.03345354, -0.0761056 , ...,  0.07538617,\n         -0.05845602,  0.12099433],\n        [ 0.06876738,  0.05425681, -0.11062171, ...,  0.05871449,\n          0.06493171,  0.12731147]],\n\n       [[ 0.00553106, -0.10793103, -0.01197037, ..., -0.09799349,\n         -0.08222825, -0.14154652],\n        [ 0.06075025, -0.07388839,  0.10538632, ...,  0.03242247,\n         -0.13218717,  0.02307361],\n        [-0.09600753,  0.10775444,  0.06762795, ...,  0.03718959,\n          0.13840398,  0.14004773],\n        ...,\n        [-0.03155743,  0.07768556, -0.06124976, ..., -0.03593597,\n          0.01193452, -0.13682048],\n        [-0.136408  , -0.1185525 , -0.05642013, ...,  0.06110801,\n         -0.0548519 , -0.05053971],\n        [ 0.11730891, -0.12683678, -0.06509806, ...,  0.09341979,\n         -0.11208169,  0.10363081]]], dtype=float32)>, <tf.Variable 'conv1d_31/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_32/kernel:0' shape=(1, 64, 32) dtype=float32, numpy=\narray([[[ 0.18617207, -0.1190151 , -0.15213913, ...,  0.06268585,\n         -0.1949541 , -0.07893205],\n        [-0.11320299,  0.00418311, -0.08779937, ...,  0.24682456,\n         -0.1542651 , -0.11088341],\n        [ 0.19361621, -0.08268344,  0.13770497, ...,  0.03348798,\n          0.20348448,  0.19699764],\n        ...,\n        [ 0.08504218,  0.1413306 ,  0.10230482, ..., -0.0538739 ,\n          0.24543566, -0.21085972],\n        [ 0.06251132, -0.12058491, -0.07281327, ..., -0.01670623,\n         -0.04156226,  0.12352508],\n        [ 0.05886728, -0.0575155 ,  0.0089559 , ..., -0.2275474 ,\n         -0.22057462,  0.13682663]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_16/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'conv1d_30/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'conv1d_transpose_15/kernel:0' shape=(3, 64, 32) dtype=float32, numpy=\narray([[[ 0.01743081, -0.09493991,  0.02397971, ...,  0.11834547,\n          0.01319839,  0.06897981],\n        [ 0.0740373 , -0.07643043, -0.0499955 , ..., -0.10451199,\n         -0.14393039, -0.08092177],\n        [ 0.07815193, -0.0791543 , -0.13301928, ..., -0.10218558,\n          0.14228082, -0.06153672],\n        ...,\n        [-0.05830385, -0.07124418,  0.00193974, ...,  0.13897005,\n         -0.01983765,  0.02357529],\n        [ 0.13166717,  0.12548348,  0.04546499, ..., -0.04738554,\n          0.1294676 ,  0.04866153],\n        [ 0.04216658, -0.04168218,  0.02755192, ..., -0.07563907,\n          0.03093159, -0.02661341]],\n\n       [[-0.09514236, -0.00552785, -0.031021  , ...,  0.07660156,\n         -0.078469  , -0.02855392],\n        [-0.02843853, -0.12962979, -0.09942544, ..., -0.10487852,\n         -0.08519343,  0.04152319],\n        [ 0.04293796, -0.040635  , -0.05006791, ...,  0.10306762,\n         -0.04117142,  0.137171  ],\n        ...,\n        [ 0.00234085,  0.0419549 ,  0.10103545, ..., -0.00632438,\n         -0.08730933,  0.13407603],\n        [ 0.12364304,  0.08405602,  0.08143851, ...,  0.03404111,\n          0.1011124 , -0.03516564],\n        [ 0.0539683 , -0.02334692, -0.04778448, ..., -0.0381081 ,\n         -0.07651656,  0.12179554]],\n\n       [[-0.07981309,  0.06849322, -0.08983257, ..., -0.09370033,\n          0.1135824 , -0.11707897],\n        [-0.06648359, -0.12816532, -0.0341942 , ..., -0.04133203,\n          0.12775058, -0.03112596],\n        [-0.10607833, -0.09784803,  0.08413465, ...,  0.08753356,\n         -0.12152156,  0.11904055],\n        ...,\n        [-0.14330849, -0.03515641, -0.04583325, ...,  0.13622731,\n         -0.10564768, -0.09196968],\n        [ 0.02919176, -0.10115406,  0.12492681, ..., -0.11141815,\n         -0.08117295, -0.09718142],\n        [-0.06592672,  0.02346951, -0.06014579, ...,  0.05301079,\n         -0.06997462,  0.01500015]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_15/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_17/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'embeddings_vqvae:0' shape=(32, 65535) dtype=float32, numpy=\narray([[ 0.02750692,  0.00364138,  0.01445637, ..., -0.00656211,\n         0.01712495,  0.04033209],\n       [-0.04390422, -0.00263307, -0.01812875, ..., -0.01264022,\n         0.04101891,  0.00553171],\n       [-0.03456918,  0.0073159 , -0.0379118 , ...,  0.00879203,\n        -0.03785807, -0.02398562],\n       ...,\n       [-0.00478645,  0.03579688,  0.042984  , ...,  0.02592951,\n         0.00745406, -0.03788954],\n       [ 0.01733616, -0.00664086,  0.02838535, ...,  0.0401086 ,\n        -0.02424562, -0.00396083],\n       [ 0.02078224, -0.04103266, -0.01151044, ...,  0.04186524,\n        -0.0110812 , -0.02230898]], dtype=float32)>, <tf.Variable 'conv1d_32/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m     checkpoints \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(re\u001b[38;5;241m.\u001b[39mmatch(pattern, file)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(pattern, file) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(checkpoints)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mvqvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/checkpoint-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mget_last_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:886\u001b[0m, in \u001b[0;36mCheckpointLoadStatus.assert_nontrivial_match\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    880\u001b[0m unused_python_objects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    881\u001b[0m     object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m    882\u001b[0m         _objects_with_attributes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint\u001b[38;5;241m.\u001b[39mall_python_objects)) \u001b[38;5;241m-\u001b[39m\n\u001b[0;32m    883\u001b[0m     object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m    884\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint\u001b[38;5;241m.\u001b[39mobject_by_proto_id\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unused_python_objects:\n\u001b[1;32m--> 886\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    887\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNothing except the root object matched a checkpointed value. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypically this means that the checkpoint does not match the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython program. The following objects have no matching \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpointed value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(unused_python_objects)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    892\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    893\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNothing to load. No dependencies have been added to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    894\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object_graph_view\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Nothing except the root object matched a checkpointed value. Typically this means that the checkpoint does not match the Python program. The following objects have no matching checkpointed value: [<tf.Variable 'conv1d_30/kernel:0' shape=(3, 65535, 32) dtype=float32, numpy=\narray([[[ 3.1859837e-03,  2.4147369e-03, -1.6694725e-03, ...,\n         -1.8291040e-03, -2.6177289e-04,  1.7357273e-03],\n        [-2.5135255e-03, -4.5673917e-03, -2.1778131e-03, ...,\n         -3.6310772e-03,  5.4083904e-03, -1.4033807e-03],\n        [-3.5876790e-03,  7.6853437e-04, -5.6006107e-04, ...,\n         -2.2224598e-03, -1.5791086e-03,  5.4973783e-03],\n        ...,\n        [ 2.3595206e-03,  3.8966136e-03,  1.4242004e-03, ...,\n          7.7969674e-04, -3.9009377e-05,  3.9720479e-03],\n        [-3.5629433e-03, -5.4414067e-03,  4.8809741e-03, ...,\n          4.4001173e-03, -2.8449520e-03,  5.4237749e-03],\n        [ 5.4534543e-03,  4.5976443e-03, -4.3144114e-03, ...,\n          4.9228929e-03, -2.7507984e-03,  3.8739070e-03]],\n\n       [[-5.1633692e-03, -3.7718844e-03, -1.3442561e-03, ...,\n         -4.6979450e-04,  4.6077194e-03,  4.4519287e-03],\n        [-3.7826675e-03,  1.6576871e-03, -2.5718918e-03, ...,\n          4.7918493e-03, -2.2136651e-03, -4.2763511e-03],\n        [-5.1356563e-03, -1.1466434e-03, -4.8627807e-03, ...,\n         -1.7672973e-03,  3.7822593e-04,  5.2022561e-03],\n        ...,\n        [-4.2552473e-03,  2.9366547e-03, -4.1953428e-03, ...,\n          3.6285780e-03, -5.3478023e-03, -2.0406761e-03],\n        [ 3.3119433e-03, -3.6730669e-03,  1.5852344e-03, ...,\n          5.4777376e-03, -5.5082953e-03, -5.0519528e-03],\n        [-4.1364776e-03, -5.4222108e-03,  1.6961582e-03, ...,\n          4.9377559e-04, -5.1352852e-03, -4.3449025e-03]],\n\n       [[-9.5041050e-04,  1.2265798e-03, -1.9765780e-03, ...,\n          5.2515129e-03,  4.1370820e-03,  4.5987722e-03],\n        [ 6.6309096e-04, -3.5401920e-03,  1.1831312e-03, ...,\n         -3.2820432e-03, -3.3968056e-03,  3.1397166e-03],\n        [-3.3389109e-03,  1.9180365e-03, -2.9727148e-03, ...,\n         -5.3149369e-03, -3.3569559e-03, -1.0492639e-03],\n        ...,\n        [ 4.5091109e-03, -2.0903607e-03, -1.6199972e-03, ...,\n          1.3179849e-03, -8.3639100e-04, -3.6963606e-03],\n        [ 2.5240779e-03, -1.0162778e-04,  1.3731290e-03, ...,\n         -2.7470719e-03, -5.3463685e-03, -1.8320605e-04],\n        [ 4.7342153e-03, -3.6527212e-03,  4.5936638e-03, ...,\n         -5.1843957e-03,  8.0442755e-04, -1.8358382e-03]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_17/kernel:0' shape=(3, 1, 32) dtype=float32, numpy=\narray([[[-0.08154388, -0.01174907,  0.113837  ,  0.03406376,\n         -0.17679563, -0.1865876 , -0.21403912, -0.05896947,\n          0.12011567,  0.15494111,  0.08926427, -0.15880921,\n         -0.14394802, -0.19183466,  0.16731048, -0.16774364,\n          0.06706849,  0.10767704,  0.21678862,  0.22105828,\n          0.19796467,  0.09410751, -0.15758783, -0.03965096,\n         -0.12124408, -0.03522627, -0.20542282, -0.11443803,\n         -0.04697616,  0.12317649, -0.24587242,  0.00504264]],\n\n       [[-0.07125717, -0.05961129,  0.23443967, -0.20154591,\n         -0.09992261,  0.24386913,  0.18912402,  0.1030758 ,\n         -0.08639428, -0.19838227,  0.23030192,  0.07771915,\n         -0.08384305,  0.11614558,  0.12786394,  0.01417083,\n          0.1395801 , -0.05985029, -0.16185945, -0.15315463,\n          0.01897496,  0.16857064, -0.04549119,  0.14801615,\n         -0.12777439, -0.14883512, -0.13611764, -0.17222449,\n         -0.08062865, -0.1225164 , -0.24166602, -0.10236356]],\n\n       [[ 0.06882024,  0.17553851,  0.16143638, -0.02033697,\n         -0.05426991, -0.12454659,  0.15727141,  0.1670284 ,\n         -0.01172918, -0.08040185, -0.20640142,  0.18147126,\n         -0.14146501,  0.10026082,  0.18389305, -0.00745168,\n          0.10735041,  0.24109039, -0.20862548, -0.00157049,\n          0.03616625, -0.20623426,  0.03829193,  0.11895201,\n          0.2397081 ,  0.01820338, -0.04466254,  0.15929642,\n          0.0692524 , -0.1493024 ,  0.01569095, -0.20330387]]],\n      dtype=float32)>, <tf.Variable 'conv1d_31/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\narray([[[ 0.0134176 ,  0.0315565 , -0.12363406, ..., -0.10226497,\n         -0.01555102,  0.06672172],\n        [-0.03083324, -0.08332602, -0.06957403, ..., -0.05285521,\n         -0.01849659,  0.00485657],\n        [ 0.04895036, -0.0934306 ,  0.01247899, ..., -0.06719256,\n          0.00969177,  0.1022892 ],\n        ...,\n        [-0.06584523,  0.02753694,  0.10897338, ...,  0.05134931,\n          0.06056477, -0.03066645],\n        [ 0.12302774, -0.12808466,  0.08843504, ...,  0.13798133,\n          0.07368718, -0.08908799],\n        [ 0.0549835 ,  0.05663067,  0.06186938, ...,  0.1141268 ,\n          0.06791912, -0.10422354]],\n\n       [[-0.09315658,  0.10344137,  0.06282596, ..., -0.0971553 ,\n         -0.06323699,  0.0111127 ],\n        [ 0.02285658,  0.09423524, -0.09941649, ...,  0.07447423,\n          0.0666094 ,  0.13799018],\n        [-0.09526642,  0.11759356,  0.08069433, ...,  0.0256554 ,\n          0.02175219, -0.07469719],\n        ...,\n        [-0.1075101 , -0.06870235,  0.0763894 , ...,  0.0734691 ,\n          0.10942778, -0.11182983],\n        [-0.07507181, -0.08195907,  0.03617947, ..., -0.05581746,\n         -0.0361846 ,  0.02509099],\n        [ 0.02645347, -0.06087837,  0.10308607, ..., -0.11828067,\n          0.11784258,  0.02180302]],\n\n       [[ 0.05438672,  0.12130535, -0.05720047, ...,  0.10046013,\n          0.12323436,  0.06498258],\n        [-0.07752909,  0.01212832, -0.08583842, ..., -0.08754234,\n         -0.03217937, -0.13251747],\n        [-0.14246655, -0.06036015,  0.04756463, ...,  0.13602024,\n          0.11706239,  0.11196637],\n        ...,\n        [-0.04782169,  0.00249688, -0.02427036, ..., -0.09003954,\n          0.00874738, -0.12035149],\n        [ 0.01497085, -0.13379312,  0.13513541, ..., -0.07636353,\n         -0.08510918,  0.03023708],\n        [-0.04170448, -0.03197953, -0.11718769, ...,  0.06908754,\n          0.07115327, -0.10701091]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_16/kernel:0' shape=(3, 32, 64) dtype=float32, numpy=\narray([[[ 0.10989046,  0.13917348, -0.07338534, ...,  0.03600191,\n         -0.06865896,  0.13270265],\n        [ 0.00683445,  0.03824528, -0.02396804, ...,  0.0871051 ,\n          0.07592838, -0.08140943],\n        [-0.0040115 ,  0.05761859,  0.06494844, ..., -0.12997048,\n         -0.09478013, -0.11157012],\n        ...,\n        [-0.13186727,  0.13046455, -0.09267844, ..., -0.13653176,\n         -0.12463537, -0.11212747],\n        [-0.07517102,  0.03225759, -0.11844795, ..., -0.11330314,\n         -0.13146423, -0.04276993],\n        [-0.05563015, -0.12825204, -0.1267446 , ..., -0.14147122,\n          0.02683689,  0.14150465]],\n\n       [[ 0.09893382, -0.05116513,  0.06521076, ...,  0.11298025,\n          0.08167055, -0.0201943 ],\n        [-0.13439348, -0.11682215,  0.08582625, ..., -0.05620635,\n         -0.13956149,  0.08771674],\n        [-0.03171603, -0.0502078 , -0.10745776, ..., -0.08051897,\n         -0.11233965, -0.07662851],\n        ...,\n        [-0.12143491, -0.03563544,  0.12245643, ..., -0.01109846,\n          0.14301443,  0.01297021],\n        [-0.12052335, -0.03345354, -0.0761056 , ...,  0.07538617,\n         -0.05845602,  0.12099433],\n        [ 0.06876738,  0.05425681, -0.11062171, ...,  0.05871449,\n          0.06493171,  0.12731147]],\n\n       [[ 0.00553106, -0.10793103, -0.01197037, ..., -0.09799349,\n         -0.08222825, -0.14154652],\n        [ 0.06075025, -0.07388839,  0.10538632, ...,  0.03242247,\n         -0.13218717,  0.02307361],\n        [-0.09600753,  0.10775444,  0.06762795, ...,  0.03718959,\n          0.13840398,  0.14004773],\n        ...,\n        [-0.03155743,  0.07768556, -0.06124976, ..., -0.03593597,\n          0.01193452, -0.13682048],\n        [-0.136408  , -0.1185525 , -0.05642013, ...,  0.06110801,\n         -0.0548519 , -0.05053971],\n        [ 0.11730891, -0.12683678, -0.06509806, ...,  0.09341979,\n         -0.11208169,  0.10363081]]], dtype=float32)>, <tf.Variable 'conv1d_31/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_32/kernel:0' shape=(1, 64, 32) dtype=float32, numpy=\narray([[[ 0.18617207, -0.1190151 , -0.15213913, ...,  0.06268585,\n         -0.1949541 , -0.07893205],\n        [-0.11320299,  0.00418311, -0.08779937, ...,  0.24682456,\n         -0.1542651 , -0.11088341],\n        [ 0.19361621, -0.08268344,  0.13770497, ...,  0.03348798,\n          0.20348448,  0.19699764],\n        ...,\n        [ 0.08504218,  0.1413306 ,  0.10230482, ..., -0.0538739 ,\n          0.24543566, -0.21085972],\n        [ 0.06251132, -0.12058491, -0.07281327, ..., -0.01670623,\n         -0.04156226,  0.12352508],\n        [ 0.05886728, -0.0575155 ,  0.0089559 , ..., -0.2275474 ,\n         -0.22057462,  0.13682663]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_16/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'conv1d_30/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'conv1d_transpose_15/kernel:0' shape=(3, 64, 32) dtype=float32, numpy=\narray([[[ 0.01743081, -0.09493991,  0.02397971, ...,  0.11834547,\n          0.01319839,  0.06897981],\n        [ 0.0740373 , -0.07643043, -0.0499955 , ..., -0.10451199,\n         -0.14393039, -0.08092177],\n        [ 0.07815193, -0.0791543 , -0.13301928, ..., -0.10218558,\n          0.14228082, -0.06153672],\n        ...,\n        [-0.05830385, -0.07124418,  0.00193974, ...,  0.13897005,\n         -0.01983765,  0.02357529],\n        [ 0.13166717,  0.12548348,  0.04546499, ..., -0.04738554,\n          0.1294676 ,  0.04866153],\n        [ 0.04216658, -0.04168218,  0.02755192, ..., -0.07563907,\n          0.03093159, -0.02661341]],\n\n       [[-0.09514236, -0.00552785, -0.031021  , ...,  0.07660156,\n         -0.078469  , -0.02855392],\n        [-0.02843853, -0.12962979, -0.09942544, ..., -0.10487852,\n         -0.08519343,  0.04152319],\n        [ 0.04293796, -0.040635  , -0.05006791, ...,  0.10306762,\n         -0.04117142,  0.137171  ],\n        ...,\n        [ 0.00234085,  0.0419549 ,  0.10103545, ..., -0.00632438,\n         -0.08730933,  0.13407603],\n        [ 0.12364304,  0.08405602,  0.08143851, ...,  0.03404111,\n          0.1011124 , -0.03516564],\n        [ 0.0539683 , -0.02334692, -0.04778448, ..., -0.0381081 ,\n         -0.07651656,  0.12179554]],\n\n       [[-0.07981309,  0.06849322, -0.08983257, ..., -0.09370033,\n          0.1135824 , -0.11707897],\n        [-0.06648359, -0.12816532, -0.0341942 , ..., -0.04133203,\n          0.12775058, -0.03112596],\n        [-0.10607833, -0.09784803,  0.08413465, ...,  0.08753356,\n         -0.12152156,  0.11904055],\n        ...,\n        [-0.14330849, -0.03515641, -0.04583325, ...,  0.13622731,\n         -0.10564768, -0.09196968],\n        [ 0.02919176, -0.10115406,  0.12492681, ..., -0.11141815,\n         -0.08117295, -0.09718142],\n        [-0.06592672,  0.02346951, -0.06014579, ...,  0.05301079,\n         -0.06997462,  0.01500015]]], dtype=float32)>, <tf.Variable 'conv1d_transpose_15/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv1d_transpose_17/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'embeddings_vqvae:0' shape=(32, 65535) dtype=float32, numpy=\narray([[ 0.02750692,  0.00364138,  0.01445637, ..., -0.00656211,\n         0.01712495,  0.04033209],\n       [-0.04390422, -0.00263307, -0.01812875, ..., -0.01264022,\n         0.04101891,  0.00553171],\n       [-0.03456918,  0.0073159 , -0.0379118 , ...,  0.00879203,\n        -0.03785807, -0.02398562],\n       ...,\n       [-0.00478645,  0.03579688,  0.042984  , ...,  0.02592951,\n         0.00745406, -0.03788954],\n       [ 0.01733616, -0.00664086,  0.02838535, ...,  0.0401086 ,\n        -0.02424562, -0.00396083],\n       [ 0.02078224, -0.04103266, -0.01151044, ...,  0.04186524,\n        -0.0110812 , -0.02230898]], dtype=float32)>, <tf.Variable 'conv1d_32/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>]"
     ]
    }
   ],
   "source": [
    "vqvae = get_vqvae(input_shape, embedding_size, conv_filters, latent_dim)\n",
    "\n",
    "checkpoint_dir = \"./checkpoints/Waveforms_with_VQVAE\"\n",
    "def get_last_checkpoint():\n",
    "    pattern = r'checkpoint-(\\d+)\\.'\n",
    "    files = os.listdir(checkpoint_dir)\n",
    "    checkpoints = [int(re.match(pattern, file).group(1)) if re.match(pattern, file) else -1 for file in files if file.startswith(\"checkpoint\")]\n",
    "    return max(checkpoints)\n",
    "\n",
    "    \n",
    "\n",
    "vqvae.load_weights(f\"{checkpoint_dir}/checkpoint-{get_last_checkpoint()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
