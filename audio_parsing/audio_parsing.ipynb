{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.fftpack import fft\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "import pywt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUNDING_SPECIFICITY = 4\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class BaseNote(Enum):\n",
    "    C = 16.35\n",
    "    C_SHARP = 17.32\n",
    "    D = 18.35\n",
    "    D_SHARP = 19.45\n",
    "    E = 20.60\n",
    "    F = 21.83\n",
    "    F_SHARP = 23.12\n",
    "    G = 24.50\n",
    "    G_SHARP = 25.96\n",
    "    A = 27.50\n",
    "    A_SHARP = 29.14\n",
    "    B = 30.87\n",
    "    \n",
    "class MIDIPitch(Enum):\n",
    "    C0 = 12\n",
    "    C_SHARP0 = 13   \n",
    "    D0 = 14\n",
    "    D_SHARP0 = 15\n",
    "    E0 = 16\n",
    "    F0 = 17\n",
    "    F_SHARP0 = 18\n",
    "    G0 = 19\n",
    "    G_SHARP0 = 20\n",
    "    # Everything before 21 is not really in the midi-set, however this enum is also used for determining the note's positioning in sparse arrays, so I want this encompassing more than just the midi set.\n",
    "    A0 = 21\n",
    "    A_SHARP0 = 22\n",
    "    B0 = 23\n",
    "    C1 = 24\n",
    "    C_SHARP1 = 25\n",
    "    D1 = 26\n",
    "    D_SHARP1 = 27\n",
    "    E1 = 28\n",
    "    F1 = 29\n",
    "    F_SHARP1 = 30\n",
    "    G1 = 31\n",
    "    G_SHARP1 = 32\n",
    "    A1 = 33\n",
    "    A_SHARP1 = 34\n",
    "    B1 = 35\n",
    "    C2 = 36\n",
    "    C_SHARP2 = 37\n",
    "    D2 = 38\n",
    "    D_SHARP2 = 39\n",
    "    E2 = 40\n",
    "    F2 = 41\n",
    "    F_SHARP2 = 42\n",
    "    G2 = 43\n",
    "    G_SHARP2 = 44\n",
    "    A2 = 45\n",
    "    A_SHARP2 = 46\n",
    "    B2 = 47\n",
    "    C3 = 48\n",
    "    C_SHARP3 = 49\n",
    "    D3 = 50\n",
    "    D_SHARP3 = 51\n",
    "    E3 = 52\n",
    "    F3 = 53\n",
    "    F_SHARP3 = 54\n",
    "    G3 = 55\n",
    "    G_SHARP3 = 56\n",
    "    A3 = 57\n",
    "    A_SHARP3 = 58\n",
    "    B3 = 59\n",
    "    C4 = 60\n",
    "    C_SHARP4 = 61\n",
    "    D4 = 62\n",
    "    D_SHARP4 = 63\n",
    "    E4 = 64\n",
    "    F4 = 65\n",
    "    F_SHARP4 = 66\n",
    "    G4 = 67\n",
    "    G_SHARP4 = 68\n",
    "    A4 = 69\n",
    "    A_SHARP4 = 70\n",
    "    B4 = 71\n",
    "    C5 = 72\n",
    "    C_SHARP5 = 73\n",
    "    D5 = 74\n",
    "    D_SHARP5 = 75\n",
    "    E5 = 76\n",
    "    F5 = 77\n",
    "    F_SHARP5 = 78\n",
    "    G5 = 79\n",
    "    G_SHARP5 = 80\n",
    "    A5 = 81\n",
    "    A_SHARP5 = 82\n",
    "    B5 = 83\n",
    "    C6 = 84\n",
    "    C_SHARP6 = 85\n",
    "    D6 = 86\n",
    "    D_SHARP6 = 87\n",
    "    E6 = 88\n",
    "    F6 = 89\n",
    "    F_SHARP6 = 90\n",
    "    G6 = 91\n",
    "    G_SHARP6 = 92\n",
    "    A6 = 93\n",
    "    A_SHARP6 = 94\n",
    "    B6 = 95\n",
    "    C7 = 96\n",
    "    C_SHARP7 = 97\n",
    "    D7 = 98\n",
    "    D_SHARP7 = 99\n",
    "    E7 = 100\n",
    "    F7 = 101\n",
    "    F_SHARP7 = 102\n",
    "    G7 = 103\n",
    "    G_SHARP7 = 104\n",
    "    A7 = 105\n",
    "    A_SHARP7 = 106\n",
    "    B7 = 107\n",
    "    C8 = 108\n",
    "    C_SHARP8 = 109\n",
    "    D8 = 110\n",
    "    D_SHARP8 = 111\n",
    "    E8 = 112\n",
    "    F8 = 113\n",
    "    F_SHARP8 = 114\n",
    "    G8 = 115\n",
    "    G_SHARP8 = 116\n",
    "    A8 = 117\n",
    "    A_SHARP8 = 118\n",
    "    B8 = 119\n",
    "    C9 = 120\n",
    "    C_SHARP9 = 121\n",
    "    D9 = 122\n",
    "    D_SHARP9 = 123\n",
    "    E9 = 124\n",
    "    F9 = 125\n",
    "    F_SHARP9 = 126\n",
    "    G9 = 127\n",
    "    \n",
    "    \n",
    "    \n",
    "class Note:\n",
    "    def __init__(self, note: BaseNote, octave: int, velocity: float = 1.0):\n",
    "        self.note = note\n",
    "        self.octave = octave\n",
    "        self.velocity = velocity\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def from_midi_pitch(midi_pitch: MIDIPitch, velocity: float = 1.0):\n",
    "        note_name = midi_pitch.name[:-1]\n",
    "        note_octave = int(midi_pitch.name[-1])\n",
    "        \n",
    "        \n",
    "        return Note(BaseNote[note_name], note_octave, velocity)\n",
    "        \n",
    "        \n",
    "    def midi_name(self):\n",
    "        return f\"{self.note.name}{self.octave}\"\n",
    "    \n",
    "    def midi_pitch(self):\n",
    "        return  MIDIPitch[self.midi_name()].value\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Note):\n",
    "            return self.note == other.note and self.octave == other.octave\n",
    "        return False\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash((self.note.value, self.octave))\n",
    "        \n",
    "    def get_frequency(self):\n",
    "        return self.note.value * (2 ** self.octave)\n",
    "\n",
    "\n",
    "class NoteRollNote:\n",
    "    def __init__(self, note: Note, start_time: float, end_time: float = 0):\n",
    "        self.note = note\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "        \n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, NoteRollNote):\n",
    "            return self.note.__eq__(other.note)\n",
    "        return False\n",
    "        \n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(self.note.__hash__())\n",
    "    \n",
    "    def generate_wave(self, sampling_frequency):\n",
    "        duration = self.end_time - self.start_time\n",
    "        t = np.linspace(0, duration, int(duration * sampling_frequency), False)\n",
    "        wave = NoteUtilities.harmonic(t, self.note.get_frequency(), 1, -np.pi / 2) \n",
    "        # * self.note.velocity\n",
    "        \n",
    "        return wave \n",
    "        \n",
    "\n",
    "class NoteUtilities:\n",
    "    def __init__(self):\n",
    "        self.notes = list(BaseNote)\n",
    "\n",
    "    @staticmethod\n",
    "    def enumerate_circle_of_fifths(start_octave=0, end_octave=8):\n",
    "        for octave in range(start_octave, end_octave + 1):\n",
    "            for note in BaseNote:\n",
    "                yield (BaseNote(note.value), note.value * (2 ** octave), octave)\n",
    "                \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_vocab_size(start_octave=0, end_octave=8):\n",
    "        return len(MIDIPitch) \n",
    "               \n",
    "                \n",
    "    frequency_note_map = {}\n",
    "    @staticmethod\n",
    "    def get_note_from_frequency(frequency, start_octave= 0, end_octave = 8):\n",
    "        rounded_frequency = round(frequency)\n",
    "        if(round(frequency, 2) in NoteUtilities.frequency_note_map):\n",
    "            return NoteUtilities.frequency_note_map[rounded_frequency]\n",
    "        \n",
    "        closest_note: Note = None\n",
    "        min_difference = float('inf')\n",
    "        for base_note, note_frequency, octave in NoteUtilities.enumerate_circle_of_fifths(start_octave, end_octave):\n",
    "            difference = abs(frequency - note_frequency)\n",
    "            if difference < min_difference:\n",
    "                min_difference = difference\n",
    "                closest_note = Note(base_note, octave)\n",
    "            \n",
    "            # Break early, since we're now going away from the note frequency\n",
    "            if difference > min_difference:\n",
    "                break\n",
    "            \n",
    "        NoteUtilities.frequency_note_map[rounded_frequency] = closest_note\n",
    "        return closest_note\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def note_sets_to_sparse_velocity(note_sets: list[set[Note]]):\n",
    "        vocab_size = NoteUtilities.get_vocab_size()\n",
    "\n",
    "        \n",
    "        sparse_array_set: np.ndarray[np.ndarray[np.float32]] = np.zeros(len(note_sets)).astype(np.ndarray)\n",
    "\n",
    "        for idx, note_set in enumerate(note_sets):\n",
    "            # Determine the positions that the note-set occupies in the sparse array. Conveniently, this is the midi pitch (expanded) minus the first midi pitch value.\n",
    "            sparse_array: np.ndarray[np.float32] = np.zeros(vocab_size)\n",
    "            for note in note_set:\n",
    "                index = note.midi_pitch() - MIDIPitch.C0.value\n",
    "                sparse_array[index] = note.velocity\n",
    "                \n",
    "            sparse_array_set[idx] = sparse_array\n",
    "    \n",
    "        return sparse_array_set\n",
    "    \n",
    "    @staticmethod\n",
    "    def sparse_velocity_to_note_sets(sparse_array_set):\n",
    "        note_sets: list[set[Note]] = []\n",
    "        for sparse_array in sparse_array_set:\n",
    "            note_set: set[Note] = set()\n",
    "            for i, velocity in enumerate(sparse_array):\n",
    "                if velocity > 0:\n",
    "                    midi_pitch_index = i + MIDIPitch.C0.value\n",
    "                    midi_pitch = MIDIPitch(midi_pitch_index)\n",
    "                    note = Note.from_midi_pitch(midi_pitch, velocity)\n",
    "                    note_set.add(note)\n",
    "            \n",
    "            note_sets.append(note_set)\n",
    "        \n",
    "        return note_sets\n",
    "       \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_note_frequency_window_set(\n",
    "        data: np.ndarray,\n",
    "        sample_duration: float,\n",
    "        sampling_frequency: int,\n",
    "        threshold_intensity: float = 0.1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Creates windows of notes for the input duration in the form [frequency, velocity].\n",
    "        \"\"\"\n",
    "\n",
    "        windows = []\n",
    "        samples_per_duration = max(int(sample_duration * sampling_frequency), 1)\n",
    "\n",
    "        for i in range(0, len(data), samples_per_duration):\n",
    "            window = data[i : i + samples_per_duration]\n",
    "            fft_spectrum = fft(window)\n",
    "            frequencies = np.fft.fftfreq(len(fft_spectrum), 1 / sampling_frequency)\n",
    "            magnitude = np.abs(fft_spectrum)\n",
    "\n",
    "            sorted_magnitude_indices = np.argsort(magnitude)\n",
    "\n",
    "            max_magnitude_index = sorted_magnitude_indices[-1]\n",
    "            max_magnitude = magnitude[max_magnitude_index]\n",
    "            min_magnitude = threshold_intensity * max_magnitude\n",
    "\n",
    "            notes_magnitude_indices = np.where(magnitude > min_magnitude)\n",
    "\n",
    "            note_frequencies = frequencies[notes_magnitude_indices]\n",
    "            note_frequencies = note_frequencies[note_frequencies > 0]\n",
    "\n",
    "            note_velocities = magnitude[notes_magnitude_indices]\n",
    "            note_velocities = note_velocities[frequencies[notes_magnitude_indices] > 0]\n",
    "\n",
    "            windows.append((note_frequencies, note_velocities))\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def get_windowset_notes(noteset):\n",
    "        \n",
    "        note_sets: list[set[Note]] = []\n",
    "        for frequency_list, magnitude_list in noteset:\n",
    "            notes: set[Note] = set()\n",
    "            note_sets.append(notes)\n",
    "            for frequency, magnitude in zip(frequency_list, magnitude_list):\n",
    "                note = NoteUtilities.get_note_from_frequency(frequency)\n",
    "                note.velocity = magnitude\n",
    "\n",
    "                notes.add(note)\n",
    "                \n",
    "        return note_sets\n",
    "    \n",
    "        \n",
    "    def get_note_roll(note_sets, window_frame_duration, max_notes: int = 3):\n",
    "        note_roll: list[NoteRollNote] = []\n",
    "        \n",
    "        pending_notes: set[NoteRollNote] = set()\n",
    "        \n",
    "        time = 0\n",
    "        for i, note_set in enumerate(note_sets):\n",
    "            #  The next note set is ust the next set of notes. For consistency, could be the next not empty set? But that wouldn't reallllly work because of the potential for repeated tones. They would get merged.\n",
    "            next_note_set: set[Note] = note_sets[i + 1] if i + 1 < len(note_sets) else set()\n",
    "            \n",
    "            # LEt's see how the output looks if we smooth notes over.\n",
    "            # Note: After testing, this does indeed NOT work well. \n",
    "            \n",
    "            # next_note_set: set[Note] = None\n",
    "            \n",
    "            # for j in range(i + 1, len(note_sets)):\n",
    "            #     if len(note_sets[j]) > 0:\n",
    "            #         next_note_set = note_sets[j]\n",
    "            #         break\n",
    "            \n",
    "            # if next_note_set is None:\n",
    "            #     next_note_set = set()\n",
    "            \n",
    "            # check the pending_notes note set. If the note is in the next note set, dont't do anything.\n",
    "            # if it is not in the next note set, then remove it from the pending note set and add it to the note roll with end time of now.\n",
    "            \n",
    "            to_remove = set()\n",
    "            for note in pending_notes:\n",
    "                if note.note in next_note_set:\n",
    "                    continue\n",
    "                \n",
    "                note.end_time = time\n",
    "                note_roll.append(note)\n",
    "                to_remove.add(note)\n",
    "                \n",
    "            pending_notes.difference_update(to_remove)\n",
    "            \n",
    "            note_set = sorted(note_set, key=lambda note: -1 * note.velocity)\n",
    "            for note in note_set:\n",
    "                roll_note = NoteRollNote(note, time)\n",
    "                if roll_note not in pending_notes and len(pending_notes) <= max_notes:\n",
    "                    pending_notes.add(roll_note)\n",
    "            \n",
    "            time += window_frame_duration\n",
    "            time = round(time, ROUNDING_SPECIFICITY)\n",
    "            \n",
    "        note_roll = sorted(note_roll, key=lambda note: (note.start_time, note.end_time))\n",
    "        return note_roll\n",
    "    \n",
    "    def cleanup_note_roll(note_roll, min_duration=0.01):\n",
    "        cleaned_note_roll = []\n",
    "        for note in note_roll:\n",
    "            if note.end_time - note.start_time > min_duration:\n",
    "                cleaned_note_roll.append(note)\n",
    "                \n",
    "        return cleaned_note_roll\n",
    "    \n",
    "    def create_wave(note_roll, sampling_frequency):\n",
    "        length =  int(max(note.end_time for note in note_roll) * sampling_frequency)\n",
    "        output = np.zeros(length)\n",
    "        \n",
    "        # Iterate through each note, generate its wave, calculate its start index, and ADD the wave's values to the existing values at its index.\n",
    "        for note in note_roll:\n",
    "            wave = note.generate_wave(sampling_frequency)\n",
    "            start_index = int(note.start_time * sampling_frequency)\n",
    "            output[start_index : start_index + len(wave)] += wave\n",
    "        \n",
    "    \n",
    "        return output / np.max(output)\n",
    "    \n",
    "    \n",
    "    def create_midi_notes(note_roll):\n",
    "        output: np.NDArray[pretty_midi.Note] = np.zeros(len(note_roll)).astype(pretty_midi.Note)\n",
    "        \n",
    "        for i, note in enumerate(note_roll):\n",
    "            midi_note = pretty_midi.Note(\n",
    "                velocity=note.note.velocity,\n",
    "                pitch=note.note.midi_pitch(),\n",
    "                start=note.start_time,\n",
    "                end=note.end_time,\n",
    "                )\n",
    "            \n",
    "            output[i] = midi_note\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def harmonic(t, f1=1, alist=1, philist=0):\n",
    "        # If alist and Ï†list are scalar values, convert them to lists of length 1\n",
    "        if np.isscalar(alist):\n",
    "            alist = [alist]\n",
    "            \n",
    "        common_phase = philist if np.isscalar(philist) else None\n",
    "        \n",
    "        frequency_values = []\n",
    "        if common_phase is not None:\n",
    "            for i, a in enumerate(alist):\n",
    "                frequency_values.append(a * NoteUtilities.cosinewave(t, (i + 1)*f1, common_phase))\n",
    "        else:\n",
    "            for i, (a, phi) in enumerate(zip(alist, philist)):\n",
    "                frequency_values.append(a * NoteUtilities.cosinewave(t, (i + 1)*f1, phi))\n",
    "                \n",
    "        return np.sum(frequency_values, axis=0)\n",
    "    \n",
    "    def cosinewave(time , frequency = 1.0, delay=0.0):\n",
    "        return np.cos(2 * np.pi * frequency * (time - delay))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before I do this on song sections, let's make sure it works on a sine wave!\n",
    "\n",
    "fs = 44_100\n",
    "duration = 5\n",
    "\n",
    "sine_frequency = 5000\n",
    "\n",
    "n_samples = int(fs * duration)\n",
    "\n",
    "x = np.linspace(0, duration, n_samples, endpoint=False)\n",
    "y = np.sin(2 * np.pi * sine_frequency * x)\n",
    "\n",
    "\n",
    "sinewave_noteset = NoteUtilities.get_note_frequency_window_set(y, 1, fs)\n",
    "\n",
    "print(sinewave_noteset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, song_data = wavfile.read(\"./data/LZSTH (1).wav\")\n",
    "\n",
    "mono_data = song_data\n",
    "\n",
    "if song_data.shape[1] == 2:\n",
    "    mono_data = np.average(song_data, axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "time = 0.4 # seconds of audio\n",
    "sample_at_time = rate * time\n",
    "plot_fs = 10000\n",
    "n_samples = int(time * plot_fs)\n",
    "\n",
    "x = np.linspace(0, sample_at_time, n_samples).astype(np.int32)\n",
    "y = mono_data[x]\n",
    "\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The window duration is the duration of the window in whatever unit the rate references. This is seconds if using the rate reported by scipy.io.wavfile.read.\n",
    "window_duration = 0.1\n",
    "# the intensity threshold is the minimum intensity of a frequency present to be considered a note. dropping this to 0.01 results in something that sounds like an awful accordion. 0.95 sounds very blocky.\n",
    "intensity_threshold = 0.2\n",
    "\n",
    "# Performance increases as both of these numbers are increased. \n",
    "data_note_sets = NoteUtilities.get_note_frequency_window_set(mono_data, window_duration, rate, intensity_threshold)\n",
    "\n",
    "print(data_note_sets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works nicely, but the notes are very close in nature and don't give a nice representation of a musical note. Let's define our musical notation using some classes, then transform these arrays into musical notes by rounding their frequencies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out our utilities on some sample frequencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_to_c_octave_4 = NoteUtilities.get_note_from_frequency(261)\n",
    "closer_to_c_sharp_octave_4 = NoteUtilities.get_note_from_frequency(270)\n",
    "closer_to_a_sharp_octave_2 = NoteUtilities.get_note_from_frequency(116)\n",
    "\n",
    "print(close_to_c_octave_4.note.name, close_to_c_octave_4.octave)\n",
    "print(closer_to_c_sharp_octave_4.note.name, close_to_c_octave_4.octave)\n",
    "print(closer_to_a_sharp_octave_2.note.name, closer_to_a_sharp_octave_2.octave)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sinewave_noteset)\n",
    "\n",
    "note_sets = NoteUtilities.get_windowset_notes(sinewave_noteset)\n",
    "\n",
    "for note_set in note_sets:\n",
    "    for note in note_set:\n",
    "        print(note.note.name, note.octave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try this on the actual song sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "note_sets = NoteUtilities.get_windowset_notes(data_note_sets)\n",
    "\n",
    "for i, note_set in enumerate(note_sets[:10]):\n",
    "    print(F\"Set {i}:\")\n",
    "    for note in note_set:\n",
    "        print(note.note.name, note.octave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem here is we cannot estimate the note duration, but it would seem strange to replay the note over and over again just to keep the note going. So, we need that note to continue playing while it is in subsequent note sets. Ultimately, we need to be able to generate a set of notes, their start time, end times, and velocities.\n",
    "\n",
    "Each note set's interval is determined by the length of time the window represents. Each note duration is represented by how many frames the note appears in in a row, and the velocity is already known. From this, we can create our list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the maximum number of notes in any given section playing simultaneously. Notes still playing are preferred.\n",
    "max_notes = 3\n",
    "\n",
    "note_roll = NoteUtilities.get_note_roll(note_sets, window_duration, max_notes)\n",
    "clean_note_roll = NoteUtilities.cleanup_note_roll(note_roll, min_duration=0.001)\n",
    " \n",
    "for note in clean_note_roll[:10]:\n",
    "    print(note.start_time, note.end_time, note.note.note.name, note.note.octave, note.note.velocity)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = clean_note_roll[0].end_time - clean_note_roll[0].start_time\n",
    "t = np.linspace(0, duration, int(duration * rate), False)\n",
    "\n",
    "wave1 = clean_note_roll[0].generate_wave(rate)\n",
    "wave2 = clean_note_roll[1].generate_wave(rate)\n",
    "\n",
    "plt.plot(t, wave1)\n",
    "\n",
    "\n",
    "duration = clean_note_roll[1].end_time - clean_note_roll[1].start_time\n",
    "t = np.linspace(0, duration, int(duration * rate), False)\n",
    "plt.plot(t, wave2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_samples = int(rate * 10.0)\n",
    "\n",
    "wave = NoteUtilities.create_wave(clean_note_roll, rate)\n",
    "\n",
    "duration =  max(note.end_time for note in clean_note_roll)\n",
    "\n",
    "n_samples = int(duration * rate)\n",
    "\n",
    "x = np.linspace(0, duration, n_samples, endpoint=False)\n",
    "\n",
    "plt.plot(x, wave)\n",
    "\n",
    "print(len(wave))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's listen and see how good the approximation in note-form is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(wave, rate=rate)\n",
    "\n",
    "saveable  = (wave / np.max(wave))\n",
    "saveable = (wave * (2 ** 16 - 1)) - 2 ** 15\n",
    "saveable = saveable.astype(np.int16)\n",
    "\n",
    "# saveable = saveable.astype(np.int16)\n",
    "print(np.max(saveable), np.min(saveable))\n",
    "\n",
    "\n",
    "wavfile.write(\"output.wav\", rate, saveable[:int(len(saveable)/10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While generating the tones manually works, there appears to be a lot of noise. Let's try again using pretty_midi to generate the sound!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_notes = NoteUtilities.create_midi_notes(clean_note_roll)\n",
    "\n",
    "cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "cello = pretty_midi.Instrument(program=cello_program)\n",
    "\n",
    "for note in midi_notes:\n",
    "    cello.notes.append(note)\n",
    "    \n",
    "midi = pretty_midi.PrettyMIDI()\n",
    "midi.instruments.append(cello)\n",
    "\n",
    "wav = midi.synthesize(fs=rate)\n",
    "\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either way, the generated signal is similarly noisy. This is likely due to clashing notes in the song's generation. Let's try reducing the noise using a few common techniques: moving averages and wavelets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def moving_average(signal, window_size):\n",
    "    cumsum = np.cumsum(np.insert(signal, 0, 0)) \n",
    "    return (cumsum[window_size:] - cumsum[:-window_size]) / window_size\n",
    "\n",
    "ma_window_size = 20\n",
    "ma_smoothed_signal = moving_average(wave, ma_window_size)\n",
    "\n",
    "print(\"Moving average smoothed signal:\")\n",
    "Audio(ma_smoothed_signal, rate=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wavelet_denoising(signal, wavelet, level):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "    uthresh = sigma * np.sqrt(2 * np.log(len(signal)))\n",
    "    denoised_coeffs = [pywt.threshold(c, value=uthresh, mode='soft') for c in coeffs]\n",
    "    return pywt.waverec(denoised_coeffs, wavelet)\n",
    "\n",
    "\n",
    "wavelet = 'db4'\n",
    "level = 4\n",
    "wl_denoised_signal = wavelet_denoising(wave, wavelet, level)\n",
    "\n",
    "print(\"Wavelet Denoised Signal:\")\n",
    "Audio(wl_denoised_signal, rate=rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the moving average sounds less noisey and almost decent! Most importantly, key characteristics of musical nature are present, and this is something our network should learn from!\n",
    "Let's transform this into a form that is consistent regardless of the number of notes present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_velocity_set = NoteUtilities.note_sets_to_sparse_velocity(note_sets)\n",
    "print(sparse_velocity_set[100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the ability to transform a velocity set back into note sets once we have predicted new velocity sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sets_reconstructed = NoteUtilities.sparse_velocity_to_note_sets(sparse_velocity_set)\n",
    "\n",
    "any_mismatch = False\n",
    "for original_set, recon_set in zip(note_sets, note_sets_reconstructed):\n",
    "    for original, recon in zip(original_set, recon_set):\n",
    "        if original.note != recon.note or original.octave != recon.octave:\n",
    "            any_mismatch = True\n",
    "            print(\"Mismatch detected!\")\n",
    "            break\n",
    "\n",
    "if not any_mismatch:\n",
    "    print(\"No mismatches detected!\")\n",
    "    \n",
    "    \n",
    "for note in note_sets[100]:\n",
    "    print(note.note.name, note.octave, note.velocity)\n",
    "    \n",
    "for note in note_sets_reconstructed[100]:\n",
    "    print(note.note.name, note.octave, note.velocity)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have sets of consistent size, we can break these down into sequences. Each sequence will be used as input to the next sequence with an offset of one, providing input and output sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequence_length = 100\n",
    "\n",
    "\n",
    "# @njit\n",
    "def create_sequence_windows(note_sets: list[set[Note]], sequence_length: int):\n",
    "    length = len(note_sets) - sequence_length\n",
    "    \n",
    "    sequences = []\n",
    "    for i in range(length):\n",
    "        sequence = np.array([np.array(list(s)) for s in note_sets[i : i + sequence_length + 1]])\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "    return np.array(sequences)\n",
    "\n",
    "\n",
    "# @njit\n",
    "def create_training_sets(sequence_windows: list[set[Note]]):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i, sequence in enumerate(sequence_windows):\n",
    "        X.append(np.array(sequence[:-1]))\n",
    "        y.append(np.array(sequence[-1]))\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sparse_velo = NoteUtilities.note_sets_to_sparse_velocity(note_sets)\n",
    "sequence_data = create_sequence_windows(sparse_velo, sequence_length)\n",
    "X, y = create_training_sets(sequence_data)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X[0][0], y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's shape a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    vocab_size = NoteUtilities.get_vocab_size()\n",
    "    input_shape = (sequence_length, vocab_size)\n",
    "\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    lstm_layer = keras.layers.LSTM(vocab_size, activation=\"relu\")(input_layer)\n",
    "    lstm_layer = keras.layers.Reshape([vocab_size, 1])(lstm_layer)\n",
    "    lstm_layer = keras.layers.LSTM(vocab_size)(lstm_layer)\n",
    "    \n",
    "    \n",
    "    #  ReLu is perfect for the output layer because we want the vast majority of notes to have a velocity of 0 and t be inactive in the output.\n",
    "    output = keras.layers.Dense(vocab_size, activation=\"relu\")(lstm_layer)\n",
    "\n",
    "    model = keras.Model(input_layer, output)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "optimizer = keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "    mse = tf.square(y_true - y_pred)\n",
    "    positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
    "    \n",
    "    return tf.reduce_mean(mse + positive_pressure)\n",
    "\n",
    "\n",
    "loss  = mse_with_positive_pressure\n",
    "\n",
    "\n",
    "# Test out loss function!\n",
    "print(y[0].shape)\n",
    "y_true_test = y[1]\n",
    "y_pred_test = y[0]\n",
    "\n",
    "print(mse_with_positive_pressure(y_true_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "# Ensure we can fit our model:\n",
    "model.fit(X[:10], y[:10], epochs=1, batch_size=1, validation_split=0.2)\n",
    "\n",
    "print(len(X[10]), len(y[10]))\n",
    "\n",
    "y_pred_test_out = model.predict(X[9:10])\n",
    "\n",
    "\n",
    "y_true_test = y[9]\n",
    "y_pred_test = tf.squeeze(y_pred_test_out)\n",
    "\n",
    "print(f\"Loss: {loss(y_true_test, y_pred_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "    keras.callbacks.ModelCheckpoint(\"checkpoints/audio_parsing/checkpoint_{epoch}\", save_weights_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5, verbose=1, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# model.fit(X, y, epochs=epochs, batch_size=100, callbacks=callbacks, validation_split=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
