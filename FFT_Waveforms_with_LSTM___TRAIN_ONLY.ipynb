{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.fftpack import fft\n",
    "import pretty_midi\n",
    "import keras\n",
    "import re\n",
    "\n",
    "\n",
    "ROUNDING_SPECIFICITY = 4\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class BaseNote(Enum):\n",
    "    C = 16.35\n",
    "    C_SHARP = 17.32\n",
    "    D = 18.35\n",
    "    D_SHARP = 19.45\n",
    "    E = 20.60\n",
    "    F = 21.83\n",
    "    F_SHARP = 23.12\n",
    "    G = 24.50\n",
    "    G_SHARP = 25.96\n",
    "    A = 27.50\n",
    "    A_SHARP = 29.14\n",
    "    B = 30.87\n",
    "    \n",
    "class MIDIPitch(Enum):\n",
    "    C0 = 12\n",
    "    C_SHARP0 = 13   \n",
    "    D0 = 14\n",
    "    D_SHARP0 = 15\n",
    "    E0 = 16\n",
    "    F0 = 17\n",
    "    F_SHARP0 = 18\n",
    "    G0 = 19\n",
    "    G_SHARP0 = 20\n",
    "    # Everything before 21 is not really in the midi-set, however this enum is also used for determining the note's positioning in sparse arrays, so I want this encompassing more than just the midi set.\n",
    "    A0 = 21\n",
    "    A_SHARP0 = 22\n",
    "    B0 = 23\n",
    "    C1 = 24\n",
    "    C_SHARP1 = 25\n",
    "    D1 = 26\n",
    "    D_SHARP1 = 27\n",
    "    E1 = 28\n",
    "    F1 = 29\n",
    "    F_SHARP1 = 30\n",
    "    G1 = 31\n",
    "    G_SHARP1 = 32\n",
    "    A1 = 33\n",
    "    A_SHARP1 = 34\n",
    "    B1 = 35\n",
    "    C2 = 36\n",
    "    C_SHARP2 = 37\n",
    "    D2 = 38\n",
    "    D_SHARP2 = 39\n",
    "    E2 = 40\n",
    "    F2 = 41\n",
    "    F_SHARP2 = 42\n",
    "    G2 = 43\n",
    "    G_SHARP2 = 44\n",
    "    A2 = 45\n",
    "    A_SHARP2 = 46\n",
    "    B2 = 47\n",
    "    C3 = 48\n",
    "    C_SHARP3 = 49\n",
    "    D3 = 50\n",
    "    D_SHARP3 = 51\n",
    "    E3 = 52\n",
    "    F3 = 53\n",
    "    F_SHARP3 = 54\n",
    "    G3 = 55\n",
    "    G_SHARP3 = 56\n",
    "    A3 = 57\n",
    "    A_SHARP3 = 58\n",
    "    B3 = 59\n",
    "    C4 = 60\n",
    "    C_SHARP4 = 61\n",
    "    D4 = 62\n",
    "    D_SHARP4 = 63\n",
    "    E4 = 64\n",
    "    F4 = 65\n",
    "    F_SHARP4 = 66\n",
    "    G4 = 67\n",
    "    G_SHARP4 = 68\n",
    "    A4 = 69\n",
    "    A_SHARP4 = 70\n",
    "    B4 = 71\n",
    "    C5 = 72\n",
    "    C_SHARP5 = 73\n",
    "    D5 = 74\n",
    "    D_SHARP5 = 75\n",
    "    E5 = 76\n",
    "    F5 = 77\n",
    "    F_SHARP5 = 78\n",
    "    G5 = 79\n",
    "    G_SHARP5 = 80\n",
    "    A5 = 81\n",
    "    A_SHARP5 = 82\n",
    "    B5 = 83\n",
    "    C6 = 84\n",
    "    C_SHARP6 = 85\n",
    "    D6 = 86\n",
    "    D_SHARP6 = 87\n",
    "    E6 = 88\n",
    "    F6 = 89\n",
    "    F_SHARP6 = 90\n",
    "    G6 = 91\n",
    "    G_SHARP6 = 92\n",
    "    A6 = 93\n",
    "    A_SHARP6 = 94\n",
    "    B6 = 95\n",
    "    C7 = 96\n",
    "    C_SHARP7 = 97\n",
    "    D7 = 98\n",
    "    D_SHARP7 = 99\n",
    "    E7 = 100\n",
    "    F7 = 101\n",
    "    F_SHARP7 = 102\n",
    "    G7 = 103\n",
    "    G_SHARP7 = 104\n",
    "    A7 = 105\n",
    "    A_SHARP7 = 106\n",
    "    B7 = 107\n",
    "    C8 = 108\n",
    "    C_SHARP8 = 109\n",
    "    D8 = 110\n",
    "    D_SHARP8 = 111\n",
    "    E8 = 112\n",
    "    F8 = 113\n",
    "    F_SHARP8 = 114\n",
    "    G8 = 115\n",
    "    G_SHARP8 = 116\n",
    "    A8 = 117\n",
    "    A_SHARP8 = 118\n",
    "    B8 = 119\n",
    "    C9 = 120\n",
    "    C_SHARP9 = 121\n",
    "    D9 = 122\n",
    "    D_SHARP9 = 123\n",
    "    E9 = 124\n",
    "    F9 = 125\n",
    "    F_SHARP9 = 126\n",
    "    G9 = 127\n",
    "    \n",
    "    \n",
    "    \n",
    "class Note:\n",
    "    def __init__(self, note: BaseNote, octave: int, velocity: float = 1.0):\n",
    "        self.note = note\n",
    "        self.octave = octave\n",
    "        self.velocity = velocity\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def from_midi_pitch(midi_pitch: MIDIPitch, velocity: float = 1.0):\n",
    "        note_name = midi_pitch.name[:-1]\n",
    "        note_octave = int(midi_pitch.name[-1])\n",
    "        \n",
    "        \n",
    "        return Note(BaseNote[note_name], note_octave, velocity)\n",
    "        \n",
    "        \n",
    "    def midi_name(self):\n",
    "        return f\"{self.note.name}{self.octave}\"\n",
    "    \n",
    "    def midi_pitch(self):\n",
    "        return  MIDIPitch[self.midi_name()].value\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Note):\n",
    "            return self.note == other.note and self.octave == other.octave\n",
    "        return False\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash((self.note.value, self.octave))\n",
    "        \n",
    "    def get_frequency(self):\n",
    "        return self.note.value * (2 ** self.octave)\n",
    "\n",
    "\n",
    "class NoteRollNote:\n",
    "    def __init__(self, note: Note, start_time: float, end_time: float = 0):\n",
    "        self.note = note\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "        \n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, NoteRollNote):\n",
    "            return self.note.__eq__(other.note)\n",
    "        return False\n",
    "        \n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(self.note.__hash__())\n",
    "    \n",
    "    def generate_wave(self, sampling_frequency):\n",
    "        duration = self.end_time - self.start_time\n",
    "        t = np.linspace(0, duration, int(duration * sampling_frequency), False)\n",
    "        \n",
    "        wave = NoteUtilities.harmonic(t, self.note.get_frequency(), 1, -np.pi / 2) \n",
    "        # * self.note.velocity # This has a tendancy to really drown out sounds.\n",
    "        \n",
    "        return wave \n",
    "        \n",
    "\n",
    "class NoteUtilities:\n",
    "    def __init__(self):\n",
    "        self.notes = list(BaseNote)\n",
    "\n",
    "    @staticmethod\n",
    "    def enumerate_circle_of_fifths(start_octave=0, end_octave=8):\n",
    "        for octave in range(start_octave, end_octave + 1):\n",
    "            for note in BaseNote:\n",
    "                yield (BaseNote(note.value), note.value * (2 ** octave), octave)\n",
    "                \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_vocab_size(start_octave=0, end_octave=8):\n",
    "        return len(MIDIPitch) \n",
    "               \n",
    "                \n",
    "    frequency_note_map = {}\n",
    "    @staticmethod\n",
    "    def get_note_from_frequency(frequency, start_octave= 0, end_octave = 8):\n",
    "        rounded_frequency = round(frequency)\n",
    "        if(round(frequency, 2) in NoteUtilities.frequency_note_map):\n",
    "            return NoteUtilities.frequency_note_map[rounded_frequency]\n",
    "        \n",
    "        closest_note: Note = None\n",
    "        min_difference = float('inf')\n",
    "        for base_note, note_frequency, octave in NoteUtilities.enumerate_circle_of_fifths(start_octave, end_octave):\n",
    "            difference = abs(frequency - note_frequency)\n",
    "            if difference < min_difference:\n",
    "                min_difference = difference\n",
    "                closest_note = Note(base_note, octave)\n",
    "            \n",
    "            # Break early, since we're now going away from the note frequency\n",
    "            if difference > min_difference:\n",
    "                break\n",
    "            \n",
    "        NoteUtilities.frequency_note_map[rounded_frequency] = closest_note\n",
    "        return closest_note\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def note_sets_to_sparse_velocity(note_sets: list[set[Note]]):\n",
    "        vocab_size = NoteUtilities.get_vocab_size()\n",
    "\n",
    "        \n",
    "        sparse_array_set: np.ndarray[np.ndarray[np.float32]] = np.zeros(len(note_sets)).astype(np.ndarray)\n",
    "\n",
    "        for idx, note_set in enumerate(note_sets):\n",
    "            # Determine the positions that the note-set occupies in the sparse array. Conveniently, this is the midi pitch (expanded) minus the first midi pitch value.\n",
    "            sparse_array: np.ndarray[np.float32] = np.zeros(vocab_size)\n",
    "            for note in note_set:\n",
    "                index = note.midi_pitch() - MIDIPitch.C0.value\n",
    "                sparse_array[index] = note.velocity\n",
    "                \n",
    "            sparse_array_set[idx] = sparse_array\n",
    "    \n",
    "        return sparse_array_set\n",
    "    \n",
    "    @staticmethod\n",
    "    def sparse_velocity_to_note_sets(sparse_array_set):\n",
    "        note_sets: list[set[Note]] = []\n",
    "        for sparse_array in sparse_array_set:\n",
    "            note_set: set[Note] = set()\n",
    "            for i, velocity in enumerate(sparse_array):\n",
    "                if velocity > 0:\n",
    "                    midi_pitch_index = i + MIDIPitch.C0.value\n",
    "                    midi_pitch = MIDIPitch(midi_pitch_index)\n",
    "                    note = Note.from_midi_pitch(midi_pitch, velocity)\n",
    "                    note_set.add(note)\n",
    "            \n",
    "            note_sets.append(note_set)\n",
    "        \n",
    "        return note_sets\n",
    "       \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_note_frequency_window_set(\n",
    "        data: np.ndarray,\n",
    "        sample_duration: float,\n",
    "        sampling_frequency: int,\n",
    "        threshold_intensity: float = 0.1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Creates windows of notes for the input duration in the form [frequency, velocity].\n",
    "        \"\"\"\n",
    "\n",
    "        windows = []\n",
    "        samples_per_duration = max(int(sample_duration * sampling_frequency), 1)\n",
    "\n",
    "        for i in range(0, len(data), samples_per_duration):\n",
    "            window = data[i : i + samples_per_duration]\n",
    "            fft_spectrum = fft(window)\n",
    "            frequencies = np.fft.fftfreq(len(fft_spectrum), 1 / sampling_frequency)\n",
    "            magnitude = np.abs(fft_spectrum)\n",
    "\n",
    "            sorted_magnitude_indices = np.argsort(magnitude)\n",
    "\n",
    "            max_magnitude_index = sorted_magnitude_indices[-1]\n",
    "            max_magnitude = magnitude[max_magnitude_index]\n",
    "            min_magnitude = threshold_intensity * max_magnitude\n",
    "\n",
    "            notes_magnitude_indices = np.where(magnitude > min_magnitude)\n",
    "\n",
    "            note_frequencies = frequencies[notes_magnitude_indices]\n",
    "            note_frequencies = note_frequencies[note_frequencies > 0]\n",
    "\n",
    "            note_velocities = magnitude[notes_magnitude_indices]\n",
    "            note_velocities = note_velocities[frequencies[notes_magnitude_indices] > 0]\n",
    "\n",
    "            windows.append((note_frequencies, note_velocities))\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def get_windowset_notes(noteset):\n",
    "        \n",
    "        note_sets: list[set[Note]] = []\n",
    "        for frequency_list, magnitude_list in noteset:\n",
    "            notes: set[Note] = set()\n",
    "            note_sets.append(notes)\n",
    "            for frequency, magnitude in zip(frequency_list, magnitude_list):\n",
    "                note = NoteUtilities.get_note_from_frequency(frequency)\n",
    "                note.velocity = magnitude\n",
    "\n",
    "                notes.add(note)\n",
    "                \n",
    "        return note_sets\n",
    "    \n",
    "        \n",
    "    def get_note_roll(note_sets, window_frame_duration, max_notes: int = 3):\n",
    "        note_roll: list[NoteRollNote] = []\n",
    "        \n",
    "        pending_notes: set[NoteRollNote] = set()\n",
    "        \n",
    "        time = 0\n",
    "        for i, note_set in enumerate(note_sets):\n",
    "            note_set = sorted(note_set, key=lambda note: -1 * note.velocity)\n",
    "            for note in note_set:\n",
    "                roll_note = NoteRollNote(note, time)\n",
    "                roll_note.end_time = time + window_frame_duration\n",
    "                if len(pending_notes) <= max_notes:\n",
    "                    note_roll.append(roll_note)\n",
    "                #     pending_notes.add(roll_note)\n",
    "            \n",
    "            time += window_frame_duration\n",
    "            time = round(time, ROUNDING_SPECIFICITY)\n",
    "            \n",
    "        note_roll = sorted(note_roll, key=lambda note: (note.start_time, note.end_time))\n",
    "        return note_roll\n",
    "    \n",
    "    def cleanup_note_roll(note_roll, min_duration=0.01):\n",
    "        cleaned_note_roll = []\n",
    "        for note in note_roll:\n",
    "            if note.end_time - note.start_time > min_duration:\n",
    "                cleaned_note_roll.append(note)\n",
    "                \n",
    "        return cleaned_note_roll\n",
    "    \n",
    "    def create_wave(note_roll, sampling_frequency):\n",
    "        length =  int(max(note.end_time for note in note_roll) * sampling_frequency)\n",
    "        output = np.zeros(length)\n",
    "        \n",
    "        # Iterate through each note, generate its wave, calculate its start index, and ADD the wave's values to the existing values at its index.\n",
    "        for note in note_roll:\n",
    "            wave = note.generate_wave(sampling_frequency)\n",
    "            start_index = int(note.start_time * sampling_frequency)\n",
    "            output[start_index : start_index + len(wave)] += wave\n",
    "        \n",
    "    \n",
    "        return output / np.max(output)\n",
    "    \n",
    "    \n",
    "    def create_midi_notes(note_roll):\n",
    "        output: np.NDArray[pretty_midi.Note] = np.zeros(len(note_roll)).astype(pretty_midi.Note)\n",
    "        \n",
    "        for i, note in enumerate(note_roll):\n",
    "            midi_note = pretty_midi.Note(\n",
    "                velocity=note.note.velocity,\n",
    "                pitch=note.note.midi_pitch(),\n",
    "                start=note.start_time,\n",
    "                end=note.end_time,\n",
    "                )\n",
    "            \n",
    "            output[i] = midi_note\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def harmonic(t, f1=1, alist=1, philist=0):\n",
    "        # If alist and φlist are scalar values, convert them to lists of length 1\n",
    "        if np.isscalar(alist):\n",
    "            alist = [alist]\n",
    "            \n",
    "        common_phase = philist if np.isscalar(philist) else None\n",
    "        \n",
    "        frequency_values = []\n",
    "        if common_phase is not None:\n",
    "            for i, a in enumerate(alist):\n",
    "                frequency_values.append(a * NoteUtilities.cosinewave(t, (i + 1)*f1, common_phase))\n",
    "        else:\n",
    "            for i, (a, phi) in enumerate(zip(alist, philist)):\n",
    "                frequency_values.append(a * NoteUtilities.cosinewave(t, (i + 1)*f1, phi))\n",
    "                \n",
    "        return np.sum(frequency_values, axis=0)\n",
    "    \n",
    "    def cosinewave(time , frequency = 1.0, delay=0.0):\n",
    "        return np.cos(2 * np.pi * frequency * (time - delay))\n",
    "\n",
    "\n",
    "\n",
    "# @njit\n",
    "def create_sequence_windows(note_sets: list[set[Note]], sequence_length: int):\n",
    "    length = len(note_sets) - sequence_length\n",
    "    \n",
    "    sequences = []\n",
    "    for i in range(length):\n",
    "        sequence = np.array([np.array(list(s)) for s in note_sets[i : i + sequence_length + 1]])\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "    return np.array(sequences)\n",
    "\n",
    "\n",
    "# @njit\n",
    "def create_training_sets(sequence_windows: list[set[Note]]) -> tuple[np.ndarray, np.ndarray]:\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    max = 0\n",
    "    \n",
    "    for i, sequence in enumerate(sequence_windows):\n",
    "        seq_max = np.max(sequence)\n",
    "        \n",
    "        if(seq_max > max):\n",
    "            max = seq_max\n",
    "        \n",
    "        X.append(np.array(sequence[:-1]))\n",
    "        y.append(np.array(sequence[-1]))\n",
    "        \n",
    "        \n",
    "    X = X / max\n",
    "    y = y / max\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "def create_model(lstm_neurons: int = 256, sequence_length: int = 100):\n",
    "    vocab_size = NoteUtilities.get_vocab_size()\n",
    "    input_shape = (sequence_length, vocab_size)\n",
    "\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    lstm_layer = keras.layers.LSTM(lstm_neurons, activation=\"relu\", )(input_layer)\n",
    "    lstm_layer = keras.layers.Reshape([lstm_neurons, 1])(lstm_layer)\n",
    "    lstm_layer = keras.layers.LSTM(lstm_neurons)(lstm_layer)\n",
    "    \n",
    "    \n",
    "    #  ReLu is perfect for the output layer because we want the vast majority of notes to have a velocity of 0 and t be inactive in the output.\n",
    "    output = keras.layers.Dense(vocab_size, activation=\"relu\")(lstm_layer)\n",
    "\n",
    "    model = keras.Model(input_layer, output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "    mse = tf.square(y_true - y_pred)\n",
    "    positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
    "    \n",
    "    return tf.reduce_mean(mse + positive_pressure)\n",
    "\n",
    "\n",
    "\n",
    "def parse_song(song_file: str):\n",
    "    rate, song_data = wavfile.read(song_file)\n",
    "\n",
    "    mono_data = song_data\n",
    "\n",
    "    if song_data.shape[1] == 2:\n",
    "        mono_data = np.average(song_data, axis=1)\n",
    "\n",
    "    data_note_sets = NoteUtilities.get_note_frequency_window_set(mono_data, training_parameters[\"window_duration\"], rate, training_parameters[\"intensity_threshold\"])\n",
    "    note_sets = NoteUtilities.get_windowset_notes(data_note_sets)\n",
    "    sparse_velo = NoteUtilities.note_sets_to_sparse_velocity(note_sets)\n",
    "    sequence_data = create_sequence_windows(sparse_velo, training_parameters[\"sequence_length\"])\n",
    "    return create_training_sets(sequence_data)\n",
    "\n",
    "\n",
    "def parse_song_directory(directory: str):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        Xs = []\n",
    "        ys = []\n",
    "\n",
    "        for file in files:\n",
    "            full_name = os.path.abspath(os.path.join(root, file))\n",
    "            X, y = parse_song(full_name)\n",
    "            Xs.append(X)\n",
    "            ys.append(y)\n",
    "        \n",
    "        X = np.concatenate(Xs, axis=0)\n",
    "        y = np.concatenate(ys, axis=0)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "\n",
    "\n",
    "training_parameters = {\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 100,\n",
    "    \"window_duration\": 0.1,\n",
    "    \"intensity_threshold\": 0.2,\n",
    "    \"lstm_neurons\": 256,\n",
    "    \"sequence_length\": 100,\n",
    "    \"epochs\": 1000\n",
    "}\n",
    "\n",
    "checkpoint_path = \"checkpoints/FFT_Waveforms_with_LSTM/checkpoint_{epoch}\"\n",
    "directory = \"./data/Wavs\"\n",
    "\n",
    "\n",
    "\n",
    "X, y = parse_song_directory(directory)\n",
    "\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "\n",
    "# Shuffling may seem odd because we're specifically trying to learn the sequential relationship, but we also want to be able to control this with the sequence length parameter.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "shuffled_dataset = dataset.shuffle(buffer_size=len(X), reshuffle_each_iteration=True)\n",
    "shuffled_X, shuffled_y = next(iter(shuffled_dataset.batch(len(X))))\n",
    "\n",
    "# Use numpy arrays for training - this enables the use of a validation split.\n",
    "shuffled_X = shuffled_X.numpy()\n",
    "shuffled_y = shuffled_y.numpy()\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\"),\n",
    "    keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5, verbose=1, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "\n",
    "model = create_model(training_parameters[\"lstm_neurons\"])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(training_parameters[\"learning_rate\"])\n",
    "loss = mse_with_positive_pressure\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "model.fit(shuffled_X, shuffled_y, epochs=training_parameters[\"epochs\"], batch_size=training_parameters[\"batch_size\"], callbacks=callbacks, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "def get_last_checkpoint():\n",
    "    pattern = r'checkpoint_(\\d+)\\.'\n",
    "    files = os.listdir(checkpoint_dir)\n",
    "    checkpoints = [int(re.match(pattern, file).group(1)) if re.match(pattern, file) else -1 for file in files if file.startswith(\"checkpoint\")]\n",
    "    return max(checkpoints)\n",
    "\n",
    "checkpoint_path = f\"{checkpoint_dir}/checkpoint_{get_last_checkpoint()}\"\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "\n",
    "def generate_song(song_duration: float, seed_note_sets: list[set[Note]]):\n",
    "    windows_to_generate = int(song_duration / window_duration)\n",
    "    \n",
    "    input_sequence = np.array([np.vstack(NoteUtilities.note_sets_to_sparse_velocity(seed_note_sets))])\n",
    "    \n",
    "    generated = []\n",
    "    \n",
    "    for _ in range(windows_to_generate):\n",
    "        predicted_note_set = model.predict(input_sequence)\n",
    "        generated.append(predicted_note_set)\n",
    "        input_sequence = np.concatenate((input_sequence, [predicted_note_set]), axis=1)[:, 1:]\n",
    "        \n",
    "    generated_stack = np.vstack(generated)\n",
    "    generated_note_set = NoteUtilities.sparse_velocity_to_note_sets(generated_stack)   \n",
    "    return generated_note_set\n",
    "\n",
    "def generate_base_seed_set(sequence_length: int):\n",
    "    seed_note_sets = []\n",
    "    \n",
    "    for _ in range(sequence_length):\n",
    "        note_set = set()\n",
    "        note_set.add(Note(BaseNote.C, 4))\n",
    "        seed_note_sets.append(note_set)\n",
    "            \n",
    "    \n",
    "    return seed_note_sets\n",
    "\n",
    "\n",
    "def moving_average(signal, window_size):\n",
    "    cumsum = np.cumsum(np.insert(signal, 0, 0)) \n",
    "    return (cumsum[window_size:] - cumsum[:-window_size]) / window_size\n",
    "\n",
    "\n",
    "\n",
    "def save_wav(audio, rate, filename):\n",
    "    audio = (audio / np.max(audio))\n",
    "    saveable = (audio * (2 ** 16 - 1)) - 2 ** 15\n",
    "    saveable = saveable.astype(np.int16)\n",
    "    wavfile.write(filename, rate, saveable)\n",
    "\n",
    "    \n",
    "seconds_of_audio = 120\n",
    "window_duration = 0.1\n",
    "max_notes = 10\n",
    "rate = 44_100\n",
    "seed_note_sets = generate_base_seed_set(100)\n",
    "\n",
    "song = generate_song(seconds_of_audio, seed_note_sets)\n",
    "note_roll = NoteUtilities.get_note_roll(song, window_duration, max_notes)\n",
    "clean_note_roll = NoteUtilities.cleanup_note_roll(note_roll, min_duration=0)\n",
    "wave = NoteUtilities.create_wave(clean_note_roll, rate)\n",
    "\n",
    "\n",
    "ma_window_size = 20\n",
    "ma_smoothed_signal = moving_average(wave, ma_window_size)\n",
    "save_wav(wave, rate, \"./predictions/FFT_Waveforms_with_LSTM/predicted_song.wav\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
