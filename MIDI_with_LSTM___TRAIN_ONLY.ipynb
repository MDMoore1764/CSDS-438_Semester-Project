{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to purely for model training, particularly for ease of use on the HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# config\n",
    "n_files = 10 #len(filenames)\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "learning_rate = 0.005\n",
    "\n",
    "\n",
    "# load data \n",
    "data_dir = pathlib.Path('data/maestro-v2.0.0')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'maestro-v2.0.0-midi.zip',\n",
    "      origin='https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip',\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data',\n",
    "  )\n",
    "  \n",
    "  \n",
    "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
    "\n",
    "\n",
    "key_order = [\"pitch\", \"step\", \"duration\", \"velocity\"]\n",
    "def get_midi_note_data(file_path:str):\n",
    "    pm = pretty_midi.PrettyMIDI(file_path)\n",
    "    \n",
    "    sorted_notes: list = sorted(pm.instruments[0].notes, key=lambda note: note.start)\n",
    "    \n",
    "    out = {}\n",
    "    out[\"start\"] = []\n",
    "    out[\"end\"] = []\n",
    "    out[\"pitch\"] = []\n",
    "    out[\"step\"] = []\n",
    "    out[\"duration\"] = []\n",
    "    out[\"velocity\"] = []\n",
    "    \n",
    "    previous_start = 0\n",
    "    for note in sorted_notes:\n",
    "        out[\"start\"].append(note.start)\n",
    "        out[\"end\"].append(note.end)\n",
    "        out[\"duration\"].append(note.end - note.start)\n",
    "        out[\"pitch\"].append(note.pitch)\n",
    "        out[\"step\"].append(note.start - previous_start)\n",
    "        out[\"velocity\"].append(note.velocity)\n",
    "        previous_start = note.start\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "def notes_to_midi(\n",
    "  notes: pd.DataFrame,\n",
    "  out_file: str, \n",
    "  instrument_name: str,\n",
    "  velocity: int = 100,  # note loudness\n",
    ") -> pretty_midi.PrettyMIDI:\n",
    "\n",
    "  pm = pretty_midi.PrettyMIDI()\n",
    "  instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          instrument_name))\n",
    "\n",
    "  prev_start = 0\n",
    "  for i, note in notes.iterrows():\n",
    "    start = float(prev_start + note['step'])\n",
    "    end = float(start + note['duration'])\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=velocity,\n",
    "        pitch=int(note['pitch']),\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    instrument.notes.append(note)\n",
    "    prev_start = start\n",
    "    \n",
    "  pm.instruments.append(instrument)\n",
    "  pm.write(out_file)\n",
    "  return pm\n",
    "\n",
    "def getAllNotes():\n",
    "    all_notes = []\n",
    "    for f in range(n_files):\n",
    "        pm = pretty_midi.PrettyMIDI(filenames[f])\n",
    "    \n",
    "        sorted_notes: list = sorted(pm.instruments[0].notes, key=lambda note: note.start)\n",
    "        \n",
    "        out = {}\n",
    "        out[\"start\"] = []\n",
    "        out[\"end\"] = []\n",
    "        out[\"pitch\"] = []\n",
    "        out[\"step\"] = []\n",
    "        out[\"duration\"] = []\n",
    "        out[\"velocity\"] = []\n",
    "        \n",
    "        previous_start = 0\n",
    "        for note in sorted_notes:\n",
    "            out[\"start\"].append(note.start)\n",
    "            out[\"end\"].append(note.end)\n",
    "            out[\"duration\"].append(note.end - note.start)\n",
    "            out[\"pitch\"].append(note.pitch)\n",
    "            out[\"step\"].append(note.start - previous_start)\n",
    "            out[\"velocity\"].append(note.velocity)\n",
    "            previous_start = note.start\n",
    "            \n",
    "        notes = pd.DataFrame({name: np.array(value) for name, value in out.items()})\n",
    "        all_notes.append(notes)\n",
    "        \n",
    "    all_notes = pd.concat(all_notes)\n",
    "    return all_notes\n",
    "\n",
    "def create_note_sequences(dataset: tf.data.Dataset, sequence_length: int, vocab_size: int):\n",
    "\n",
    "    windows = dataset.window(sequence_length + 1, shift=1, stride=1, drop_remainder=True)\n",
    "    sequences = windows.flat_map(lambda x: x.batch(sequence_length + 1, drop_remainder=True))\n",
    "    \n",
    "\n",
    "    def scale_pitch(x):\n",
    "        \n",
    "        pitch_scale = float(vocab_size)\n",
    "        step_scale = 1.0\n",
    "        duration_scale = 1.0\n",
    "        velocity_scale = 1.0\n",
    "        \n",
    "        return tf.divide(x, tf.constant([pitch_scale, step_scale, duration_scale, velocity_scale], dtype= tf.float64))\n",
    "\n",
    "    \n",
    "    def split_labels(sequences):\n",
    "        inputs = sequences[:-1]\n",
    "        labels_dense = sequences[-1]\n",
    "        labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
    "            \n",
    "        return scale_pitch(inputs), labels\n",
    "\n",
    "\n",
    "    return sequences.map(split_labels, tf.data.AUTOTUNE)\n",
    "\n",
    "      \n",
    "      \n",
    "all_notes = getAllNotes()\n",
    "\n",
    "seq_length = 100\n",
    "vocab_size = np.max(all_notes[\"pitch\"].unique()) + 1\n",
    "max_velocity = np.max(all_notes[\"velocity\"]) + 1\n",
    "\n",
    "notes_by_column = [all_notes[key].to_numpy() for key in key_order]\n",
    "stacked_notes = np.stack(notes_by_column, axis=1)\n",
    "\n",
    "notes_ds = tf.data.Dataset.from_tensor_slices(stacked_notes)\n",
    "\n",
    "\n",
    "seq_ds = create_note_sequences(notes_ds, seq_length, vocab_size)\n",
    "\n",
    "batch_size = 64\n",
    "buffer_size = len(all_notes)\n",
    "training_ds = seq_ds.shuffle(buffer_size).batch(batch_size, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def mse_with_positive_presssure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "    mse = tf.square(y_true - y_pred)\n",
    "    positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
    "    \n",
    "    return tf.reduce_mean(mse + positive_pressure)\n",
    "\n",
    "loss = {\n",
    "    \"pitch\": keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    \"step\": mse_with_positive_presssure,\n",
    "    \"duration\": mse_with_positive_presssure,\n",
    "    \"velocity\": keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "}\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    input_shape = (seq_length, len(key_order))\n",
    "\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    lstm_layer = keras.layers.LSTM(vocab_size)(input_layer)\n",
    "    lstm_layer = keras.layers.Reshape([vocab_size, 1])(lstm_layer)\n",
    "    lstm_layer = keras.layers.LSTM(vocab_size)(lstm_layer)\n",
    "\n",
    "    outputs = {\n",
    "        \"pitch\": keras.layers.Dense(vocab_size, name = 'pitch')(lstm_layer),\n",
    "        \"step\": keras.layers.Dense(1, name=\"step\")(lstm_layer),\n",
    "        \"duration\": keras.layers.Dense(1, name=\"duration\")(lstm_layer),\n",
    "        \"velocity\": keras.layers.Dense(max_velocity, name=\"velocity\")(lstm_layer)\n",
    "    }\n",
    "\n",
    "    model = keras.Model(input_layer, outputs)\n",
    "\n",
    "    model.compile(optimizer, loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "losses = model.evaluate(training_ds, return_dict=True)\n",
    "loss_weights = {key: 1 / losses[f\"{key}_loss\"] * (len(losses) - 1) for key in key_order}\n",
    "weighted_losses = {key: loss_weights[key]*losses[f\"{key}_loss\"] for key in loss_weights}\n",
    "\n",
    "model.compile(optimizer, loss, loss_weights = loss_weights)\n",
    "\n",
    "new_losses = model.evaluate(training_ds, return_dict=True)\n",
    "\n",
    "callbacks = [\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"loss\"),\n",
    "    keras.callbacks.ModelCheckpoint(\"checkpoints/MIDI_with_LSTM/checkpoint_{epoch}\", save_weights_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5, verbose=1, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "history = model.fit(training_ds, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "import os\n",
    "import re\n",
    "from scipy.io import wavfile\n",
    "\n",
    "_SAMPLING_RATE = 16_000\n",
    "\n",
    "def predict_next_note(\n",
    "    notes: np.ndarray, \n",
    "    model: tf.keras.Model, \n",
    "    temperature: float = 1.0) -> tuple[int, float, float]:\n",
    "\n",
    "  assert temperature > 0\n",
    "\n",
    "  # Add batch dimension\n",
    "  inputs = tf.expand_dims(notes, 0)\n",
    "\n",
    "  predictions = model.predict(inputs)\n",
    "  pitch_logits = predictions['pitch']\n",
    "  step = predictions['step']\n",
    "  duration = predictions['duration']\n",
    "  velocity_logits = predictions['velocity']\n",
    "\n",
    "  pitch_logits /= temperature\n",
    "  velocity_logits /= temperature\n",
    "  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
    "  pitch = tf.squeeze(pitch, axis=-1)\n",
    "  duration = tf.squeeze(duration, axis=-1)\n",
    "  step = tf.squeeze(step, axis=-1)\n",
    "  velocity = tf.random.categorical(velocity_logits, num_samples=1)\n",
    "  velocity = tf.squeeze(velocity, axis = -1)\n",
    "\n",
    "  step = tf.maximum(0, step)\n",
    "  duration = tf.maximum(0, duration)\n",
    "\n",
    "  return int(pitch), float(step), float(duration), int(velocity)\n",
    "\n",
    "\n",
    "def save_wav(audio, rate, filename):\n",
    "    audio = (audio / np.max(audio))\n",
    "    saveable = (audio * (2 ** 16 - 1)) - 2 ** 15\n",
    "    saveable = saveable.astype(np.int16)\n",
    "    wavfile.write(filename, rate, saveable)\n",
    "\n",
    "\n",
    "temperature = 1.1\n",
    "num_predictions = 5000\n",
    "\n",
    "checkpoint_dir = \"checkpoints/MIDI_with_LSTM\"\n",
    "def get_last_checkpoint():\n",
    "    pattern = r'checkpoint_(\\d+)\\.'\n",
    "    files = os.listdir(checkpoint_dir)\n",
    "    checkpoints = [int(re.match(pattern, file).group(1)) if re.match(pattern, file) else -1 for file in files if file.startswith(\"checkpoint\")]\n",
    "    return max(checkpoints)\n",
    "\n",
    "checkpoint_path = f\"{checkpoint_dir}/checkpoint_{get_last_checkpoint()}\"\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "example = filenames[0]\n",
    "raw_notes = get_midi_note_data(example)\n",
    "sample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)\n",
    "\n",
    "input_notes = (\n",
    "    sample_notes[:seq_length] / np.array([vocab_size, 1, 1, 1]))\n",
    "\n",
    "generated_notes = []\n",
    "prev_start = 0\n",
    "for _ in range(num_predictions):\n",
    "  pitch, step, duration, velocity = predict_next_note(input_notes, model, temperature)\n",
    "  start = prev_start + step\n",
    "  end = start + duration\n",
    "  input_note = (pitch, step, duration, velocity)\n",
    "  generated_notes.append((*input_note, start, end))\n",
    "  input_notes = np.delete(input_notes, 0, axis=0)\n",
    "  input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)\n",
    "  prev_start = start\n",
    "\n",
    "generated_notes = pd.DataFrame(\n",
    "    generated_notes, columns=(*key_order, 'start', 'end'))\n",
    "\n",
    "\n",
    "instrument_name = pretty_midi.program_to_instrument_name(pretty_midi.PrettyMIDI(example).instruments[0].program)\n",
    "midi = notes_to_midi(generated_notes, \"test_outputs/MIDI_with_LSTM/test.midi\", instrument_name, 100)\n",
    "\n",
    "synth = midi.synthesize(_SAMPLING_RATE)\n",
    "midi.write(\"predictions/MIDI_with_LSTM/example.midi\")\n",
    "    \n",
    "save_wav(synth, _SAMPLING_RATE, \"predictions/MIDI_with_LSTM/example.wav\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
