{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: Take a collection of songs from a directory. Each folder will contain the song and a text file of labels. The song will be wav, text file will be comma separated labels.\n",
    "\n",
    "ALL label files will be loaded and a vocabulary will be generated and embedded, this will be used as one input vector to the network.\n",
    "\n",
    "The song vocabulary will be an embedding of 2 ** 16 -1 values (all uint16 values). These will be embedded into an input vector as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Vocabulary Length:\n",
      "11\n",
      "Index-encoded Label:\n",
      "5\n",
      "Label at index:\n",
      "mario\n",
      "Song labels:\n",
      "['mario', 'super', 'bit', '8bit', '8-bit', 'nes', 'nintendo', 'game', 'video', 'sm64']\n",
      "Vectorized Labels:\n",
      "[ 5  9  3  2  1  6  7  4 10  8]\n",
      "Song title:\n",
      "sm64\n",
      "Sample Rate:\n",
      "44100\n",
      "Song Data Shape:\n",
      "(36097889,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import re\n",
    "\n",
    "ROOT = \"./data\"\n",
    "\n",
    "def clean_label(label: str):\n",
    "    return label.strip(\" :,;_-.><[]{}\")\n",
    "\n",
    "def generate_label_vocabulary(source: str):\n",
    "    directories = os.listdir(source)\n",
    "    \n",
    "    all_labels = set()\n",
    "    all_labels.add(\"\")\n",
    "    \n",
    "    for song_directory in directories:\n",
    "        full_song_directory = os.path.join(source, song_directory)\n",
    "        files = os.listdir(full_song_directory)\n",
    "        \n",
    "        for song_file in files:\n",
    "            full_song_file = os.path.join(full_song_directory, song_file)\n",
    "            \n",
    "\n",
    "            \n",
    "            if not full_song_file.endswith(\".labels\"):\n",
    "                title = os.path.splitext(song_file)[0]\n",
    "                all_labels.add(clean_label(title))\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            with open(full_song_file, 'r') as label_file:\n",
    "                labels = label_file.read().split(\",\")\n",
    "                all_labels = all_labels.union(labels)\n",
    "     \n",
    "    word_to_index = {}\n",
    "    index_to_word = np.ndarray(shape=(len(all_labels)), dtype=np.object_)\n",
    "    for i, label in enumerate(sorted(all_labels)):\n",
    "        clean = clean_label(label)\n",
    "        word_to_index[clean] = i\n",
    "        index_to_word[i] = clean\n",
    "\n",
    "    \n",
    "    return word_to_index, index_to_word\n",
    "     \n",
    "     \n",
    "def vectorize_labels(labels: list[str], word_to_index: dict[str, int]):\n",
    "       return np.array([word_to_index[label] for label in labels])\n",
    "   \n",
    "   \n",
    "def normalize_song(song: np.ndarray):\n",
    "    song = song / np.max(song)\n",
    "    \n",
    "    \n",
    "    mean = np.mean(song)\n",
    "    std = np.std(song)\n",
    "    normalized = (song - mean) / std\n",
    "    \n",
    "    normalized_reduced_size = normalized.astype(np.float16)\n",
    "    return normalized_reduced_size\n",
    "        \n",
    "def load_song_data(directory: str):\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    title: str\n",
    "    labels: list[str]\n",
    "    song: np.ndarray\n",
    "    sample_rate: np.int32\n",
    "    \n",
    "    for song_file in files:\n",
    "        full_song_file = os.path.join(directory, song_file)\n",
    "        if full_song_file.endswith(\".labels\"):\n",
    "            with open(full_song_file, 'r') as label_file:\n",
    "                labels = label_file.read().split(\",\")\n",
    "                labels = [clean_label(label) for label in labels]\n",
    "                continue\n",
    "        \n",
    "        title = os.path.splitext(song_file)[0]\n",
    "        labels.append(clean_label(title))\n",
    "        sample_rate, song = wavfile.read(full_song_file)\n",
    "        \n",
    "    return labels, title, song, sample_rate\n",
    "            \n",
    "        \n",
    "    \n",
    "word_to_index, index_to_word = generate_label_vocabulary(ROOT)\n",
    "vocab_size = len(word_to_index.items())\n",
    "\n",
    "print(\"Label Vocabulary Length:\")\n",
    "print(vocab_size)\n",
    "\n",
    "mario_index = word_to_index.get(\"mario\")\n",
    "word_at_mario_index = index_to_word[mario_index]\n",
    "\n",
    "print(\"Index-encoded Label:\")\n",
    "print(mario_index)\n",
    "\n",
    "print(\"Label at index:\")\n",
    "print(word_at_mario_index)\n",
    "    \n",
    "    \n",
    "example_song_directory = os.path.join(ROOT, \"Super Mario\")\n",
    "\n",
    "labels, title, song_data, sample_rate = load_song_data(example_song_directory)\n",
    "\n",
    "print(\"Song labels:\")\n",
    "print(labels)\n",
    "\n",
    "print(\"Vectorized Labels:\")\n",
    "print(vectorize_labels(labels, word_to_index))\n",
    "\n",
    "print(\"Song title:\")\n",
    "print(title)\n",
    "\n",
    "print(\"Sample Rate:\")\n",
    "print(sample_rate)\n",
    "\n",
    "print(\"Song Data Shape:\")\n",
    "\n",
    "print(song_data.shape)\n",
    "\n",
    "\n",
    "                \n",
    "                    \n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a vocabulary generated and the song data loaded, we need to transform that data into forms that a neural network can consume. But that begs the question \"what does the neural network LOOK like?\"\n",
    "\n",
    "There will be two inputs to the network: the encoded labels, and the song data:\n",
    "The encoded labels will be transformed into an embedding.\n",
    "\n",
    "The song data will be normalized and cut up into predictive segements: each previous segment being used to predict the segment that follows. This will be learned using an LSTM.\n",
    "\n",
    "The outputs will then be concatenated and an output dense layer will predict the generated amplitude value of the waveform given a previous segment and a set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Labels:\n",
      "(1, 11)\n",
      "Song Data:\n",
      "(1, 1000, 1)\n",
      "Prediction (:10): \n",
      "tf.Tensor(\n",
      "[0.4997029  0.5090413  0.49525148 0.50307536 0.49385962 0.4905735\n",
      " 0.49291262 0.50268656 0.5028553  0.5057263 ], shape=(10,), dtype=float32)\n",
      "Model Summary:\n",
      "Model: \"Song_Sequence_Predictor\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Label_Input (InputLayer)    [(None, 11)]                 0         []                            \n",
      "                                                                                                  \n",
      " Label_Embedding (Embedding  (None, 11, 99)               1089      ['Label_Input[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Song_Sequence_Input (Input  [(None, 1000, 1)]            0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " Label_Flattening (Flatten)  (None, 1089)                 0         ['Label_Embedding[0][0]']     \n",
      "                                                                                                  \n",
      " Song_Sequence_LSTM (LSTM)   (None, 99)                   39996     ['Song_Sequence_Input[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenat  (None, 1188)                 0         ['Label_Flattening[0][0]',    \n",
      " e)                                                                  'Song_Sequence_LSTM[0][0]']  \n",
      "                                                                                                  \n",
      " Combined_Learning_Layer (D  (None, 256)                  304384    ['concatenate_17[0][0]']      \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " Amplitude_Prediction_Layer  (None, 1000)                 257000    ['Combined_Learning_Layer[0][0\n",
      "  (Dense)                                                           ]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 602469 (2.30 MB)\n",
      "Trainable params: 602469 (2.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# There are a few problems with this model. 1. It's a simple LSTM model. 2. The concat label and song layers hardly makes any sense,\n",
    "def build_model(song_sequence_length: int, combined_layer_units: int, rnn_units: int):\n",
    "    label_input = keras.layers.Input(shape=vocab_size, name=\"Label_Input\")\n",
    "    label_embedding = keras.layers.Embedding(vocab_size, rnn_units, input_length=None, name=\"Label_Embedding\")(label_input)\n",
    "    \n",
    "    label_out = keras.layers.Flatten(name=\"Label_Flattening\")(label_embedding)\n",
    "    \n",
    "    \n",
    "    song_input = keras.layers.Input(shape=(song_sequence_length, 1), name=\"Song_Sequence_Input\")\n",
    "    song_lstm = keras.layers.LSTM(rnn_units, activation=keras.activations.relu,  name=\"Song_Sequence_LSTM\")(song_input)\n",
    "    \n",
    "    \n",
    "    concat = keras.layers.concatenate([label_out, song_lstm], axis = -1)\n",
    "    combined_learning_layer = keras.layers.Dense(combined_layer_units, activation=keras.activations.relu, name=\"Combined_Learning_Layer\")(concat)\n",
    "    \n",
    "    \n",
    "    predictive_layer = keras.layers.Dense(song_sequence_length, activation=\"sigmoid\", name=\"Amplitude_Prediction_Layer\")(combined_learning_layer)\n",
    "    \n",
    "    \n",
    "    model =  keras.Model(inputs=[label_input, song_input], outputs = predictive_layer, name=\"Song_Sequence_Predictor\", )\n",
    "    return model\n",
    "\n",
    "def pad_label_vector(label_vector: np.ndarray, vocab_size: int):\n",
    "    return np.pad(label_vector, (0, vocab_size - len(label_vector)))\n",
    "    \n",
    "\n",
    "sequence_length = 1_000\n",
    "\n",
    "model = build_model(sequence_length, 256, 99)\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.000001)\n",
    "loss = keras.losses.mean_squared_error\n",
    "model.compile(opt, loss, metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "example_song_directory = os.path.join(ROOT, \"Super Mario\")\n",
    "labels, title, song_data, sample_rate = load_song_data(example_song_directory)\n",
    "\n",
    "\n",
    "\n",
    "vectorized = pad_label_vector(vectorize_labels(labels, word_to_index), vocab_size)\n",
    "vectorized = tf.expand_dims(vectorized, 0)\n",
    "\n",
    "\n",
    "song_chunk =  tf.expand_dims(tf.expand_dims(normalize_song(song_data)[:sequence_length], 1), 0)\n",
    "\n",
    "\n",
    "print(\"Vectorized Labels:\")\n",
    "print(vectorized.shape)\n",
    "\n",
    "print(\"Song Data:\")\n",
    "print(song_chunk.shape)\n",
    "\n",
    "print(\"Prediction (:10): \")\n",
    "result = model([vectorized, song_chunk])[0][:10]\n",
    "print(result)\n",
    "\n",
    "print(\"Model Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a basic model together, we can transform data into inputs and outputs, and train the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "565/565 [==============================] - 476s 843ms/step - loss: nan - accuracy: 0.1006\n",
      "Epoch 2/10\n",
      "565/565 [==============================] - 502s 889ms/step - loss: nan - accuracy: 0.1006\n",
      "Epoch 3/10\n",
      "565/565 [==============================] - 566s 1s/step - loss: nan - accuracy: 0.1006\n",
      "Epoch 4/10\n",
      "565/565 [==============================] - 546s 966ms/step - loss: nan - accuracy: 0.1006\n",
      "Epoch 5/10\n",
      "565/565 [==============================] - 549s 972ms/step - loss: nan - accuracy: 0.1006\n",
      "Epoch 6/10\n",
      "565/565 [==============================] - 535s 946ms/step - loss: nan - accuracy: 0.1006\n",
      "Epoch 7/10\n",
      "565/565 [==============================] - 493s 872ms/step - loss: nan - accuracy: 0.1006\n",
      "Epoch 8/10\n",
      "565/565 [==============================] - 484s 857ms/step - loss: nan - accuracy: 0.1006\n",
      "Epoch 9/10\n",
      "565/565 [==============================] - 485s 858ms/step - loss: nan - accuracy: 0.1006\n",
      "Epoch 10/10\n",
      "565/565 [==============================] - 490s 867ms/step - loss: nan - accuracy: 0.1006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23e783c0f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_song_datasets(labels: list[str], vocab_size:int, word_to_index: dict, song_data:np.ndarray, sequence_length: int):\n",
    "    # Vectorize the dataset into as many inputs as there are song sets.\n",
    "    # vectorized = tf.expand_dims(tf.expand_dims(vectorize_labels(labels, word_to_index), 1), 0)\n",
    "    \n",
    "    sequences = []\n",
    "    \n",
    "    for i in range(0, len(song_data), sequence_length):\n",
    "        sequence = song_data[i:i + sequence_length]\n",
    "        if len(sequence) < sequence_length:\n",
    "            sequence = np.pad(sequence, (0, sequence_length - len(sequence)))\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "    x = np.array(sequences[:-1])\n",
    "    y = np.array(sequences[1:])\n",
    "    \n",
    "    vectorized = pad_label_vector(vectorize_labels(labels, word_to_index), vocab_size)\n",
    "    vectorized_set = np.array([vectorized] * len(x))\n",
    "    \n",
    "    return vectorized_set, x, y\n",
    "    \n",
    "\n",
    "    \n",
    "example_song_directory = os.path.join(ROOT, \"Super Mario\")\n",
    "labels, title, song_data, sample_rate = load_song_data(example_song_directory)\n",
    "\n",
    "\n",
    "labels, x, y = generate_song_datasets(labels, vocab_size, word_to_index, song_data, sequence_length)\n",
    "\n",
    "model.fit([labels, x], y, epochs=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
