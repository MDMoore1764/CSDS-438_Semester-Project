{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: Take a collection of songs from a directory. Each folder will contain the song and a text file of labels. The song will be wav, text file will be comma separated labels.\n",
    "\n",
    "ALL label files will be loaded and a vocabulary will be generated and embedded, this will be used as one input vector to the network.\n",
    "\n",
    "The song vocabulary will be an embedding of 2 ** 16 -1 values (all uint16 values). These will be embedded into an input vector as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Vocabulary Length:\n",
      "11\n",
      "Index-encoded Label:\n",
      "5\n",
      "Label at index:\n",
      "mario\n",
      "Song labels:\n",
      "['mario', 'super', 'bit', '8bit', '8-bit', 'nes', 'nintendo', 'game', 'video', 'sm64']\n",
      "Vectorized Labels:\n",
      "[ 5  9  3  2  1  6  7  4 10  8]\n",
      "Song title:\n",
      "sm64\n",
      "Sample Rate:\n",
      "44100\n",
      "Song Data Shape:\n",
      "(36097889,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import re\n",
    "\n",
    "ROOT = \"./data\"\n",
    "\n",
    "def clean_label(label: str):\n",
    "    return label.strip(\" :,;_-.><[]{}\")\n",
    "\n",
    "def generate_label_vocabulary(source: str):\n",
    "    directories = os.listdir(source)\n",
    "    \n",
    "    all_labels = set()\n",
    "    all_labels.add(\"\")\n",
    "    \n",
    "    for song_directory in directories:\n",
    "        full_song_directory = os.path.join(source, song_directory)\n",
    "        files = os.listdir(full_song_directory)\n",
    "        \n",
    "        for song_file in files:\n",
    "            full_song_file = os.path.join(full_song_directory, song_file)\n",
    "            \n",
    "\n",
    "            \n",
    "            if not full_song_file.endswith(\".labels\"):\n",
    "                title = os.path.splitext(song_file)[0]\n",
    "                all_labels.add(clean_label(title))\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            with open(full_song_file, 'r') as label_file:\n",
    "                labels = label_file.read().split(\",\")\n",
    "                all_labels = all_labels.union(labels)\n",
    "     \n",
    "    word_to_index = {}\n",
    "    index_to_word = np.ndarray(shape=(len(all_labels)), dtype=np.object_)\n",
    "    for i, label in enumerate(sorted(all_labels)):\n",
    "        clean = clean_label(label)\n",
    "        word_to_index[clean] = i\n",
    "        index_to_word[i] = clean\n",
    "\n",
    "    \n",
    "    return word_to_index, index_to_word\n",
    "     \n",
    "     \n",
    "def vectorize_labels(labels: list[str], word_to_index: dict[str, int]):\n",
    "       return np.array([word_to_index[label] for label in labels])\n",
    "   \n",
    "   \n",
    "def normalize_song(song: np.ndarray):\n",
    "    song = song / np.max(song)\n",
    "    \n",
    "    \n",
    "    mean = np.mean(song)\n",
    "    std = np.std(song)\n",
    "    normalized = (song - mean) / std\n",
    "    \n",
    "    normalized_reduced_size = normalized.astype(np.float16)\n",
    "    return normalized_reduced_size\n",
    "        \n",
    "def load_song_data(directory: str):\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    title: str\n",
    "    labels: list[str]\n",
    "    song: np.ndarray\n",
    "    sample_rate: np.int32\n",
    "    \n",
    "    for song_file in files:\n",
    "        full_song_file = os.path.join(directory, song_file)\n",
    "        if full_song_file.endswith(\".labels\"):\n",
    "            with open(full_song_file, 'r') as label_file:\n",
    "                labels = label_file.read().split(\",\")\n",
    "                labels = [clean_label(label) for label in labels]\n",
    "                continue\n",
    "        \n",
    "        title = os.path.splitext(song_file)[0]\n",
    "        labels.append(clean_label(title))\n",
    "        sample_rate, song = wavfile.read(full_song_file)\n",
    "        \n",
    "    return labels, title, song, sample_rate\n",
    "            \n",
    "        \n",
    "    \n",
    "word_to_index, index_to_word = generate_label_vocabulary(ROOT)\n",
    "vocab_size = len(word_to_index.items())\n",
    "\n",
    "print(\"Label Vocabulary Length:\")\n",
    "print(vocab_size)\n",
    "\n",
    "mario_index = word_to_index.get(\"mario\")\n",
    "word_at_mario_index = index_to_word[mario_index]\n",
    "\n",
    "print(\"Index-encoded Label:\")\n",
    "print(mario_index)\n",
    "\n",
    "print(\"Label at index:\")\n",
    "print(word_at_mario_index)\n",
    "    \n",
    "    \n",
    "example_song_directory = os.path.join(ROOT, \"Super Mario\")\n",
    "\n",
    "labels, title, song_data, sample_rate = load_song_data(example_song_directory)\n",
    "\n",
    "print(\"Song labels:\")\n",
    "print(labels)\n",
    "\n",
    "print(\"Vectorized Labels:\")\n",
    "print(vectorize_labels(labels, word_to_index))\n",
    "\n",
    "print(\"Song title:\")\n",
    "print(title)\n",
    "\n",
    "print(\"Sample Rate:\")\n",
    "print(sample_rate)\n",
    "\n",
    "print(\"Song Data Shape:\")\n",
    "\n",
    "print(song_data.shape)\n",
    "\n",
    "\n",
    "                \n",
    "                    \n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a vocabulary generated and the song data loaded, we need to transform that data into forms that a neural network can consume. But that begs the question \"what does the neural network LOOK like?\"\n",
    "\n",
    "There will be two inputs to the network: the encoded labels, and the song data:\n",
    "The encoded labels will be transformed into an embedding.\n",
    "\n",
    "The song data will be normalized and cut up into predictive segements: each previous segment being used to predict the segment that follows. This will be learned using an LSTM.\n",
    "\n",
    "The outputs will then be concatenated and an output dense layer will predict the generated amplitude value of the waveform given a previous segment and a set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Labels:\n",
      "(1, 11)\n",
      "Song Data:\n",
      "(1, 1000, 1)\n",
      "Prediction (:10): \n",
      "tf.Tensor(\n",
      "[0.4997029  0.5090413  0.49525148 0.50307536 0.49385962 0.4905735\n",
      " 0.49291262 0.50268656 0.5028553  0.5057263 ], shape=(10,), dtype=float32)\n",
      "Model Summary:\n",
      "Model: \"Song_Sequence_Predictor\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Label_Input (InputLayer)    [(None, 11)]                 0         []                            \n",
      "                                                                                                  \n",
      " Label_Embedding (Embedding  (None, 11, 99)               1089      ['Label_Input[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Song_Sequence_Input (Input  [(None, 1000, 1)]            0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " Label_Flattening (Flatten)  (None, 1089)                 0         ['Label_Embedding[0][0]']     \n",
      "                                                                                                  \n",
      " Song_Sequence_LSTM (LSTM)   (None, 99)                   39996     ['Song_Sequence_Input[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenat  (None, 1188)                 0         ['Label_Flattening[0][0]',    \n",
      " e)                                                                  'Song_Sequence_LSTM[0][0]']  \n",
      "                                                                                                  \n",
      " Combined_Learning_Layer (D  (None, 256)                  304384    ['concatenate_17[0][0]']      \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " Amplitude_Prediction_Layer  (None, 1000)                 257000    ['Combined_Learning_Layer[0][0\n",
      "  (Dense)                                                           ]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 602469 (2.30 MB)\n",
      "Trainable params: 602469 (2.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# There are a few problems with this model. 1. It's a simple LSTM model. 2. The concat label and song layers hardly makes any sense,\n",
    "def build_model(song_sequence_length: int, combined_layer_units: int, rnn_units: int):\n",
    "    label_input = keras.layers.Input(shape=vocab_size, name=\"Label_Input\")\n",
    "    label_embedding = keras.layers.Embedding(vocab_size, rnn_units, input_length=None, name=\"Label_Embedding\")(label_input)\n",
    "    \n",
    "    label_out = keras.layers.Flatten(name=\"Label_Flattening\")(label_embedding)\n",
    "    \n",
    "    \n",
    "    song_input = keras.layers.Input(shape=(song_sequence_length, 1), name=\"Song_Sequence_Input\")\n",
    "    song_lstm = keras.layers.LSTM(rnn_units, activation=keras.activations.relu,  name=\"Song_Sequence_LSTM\")(song_input)\n",
    "    \n",
    "    \n",
    "    concat = keras.layers.concatenate([label_out, song_lstm], axis = -1)\n",
    "    combined_learning_layer = keras.layers.Dense(combined_layer_units, activation=keras.activations.relu, name=\"Combined_Learning_Layer\")(concat)\n",
    "    \n",
    "    \n",
    "    predictive_layer = keras.layers.Dense(song_sequence_length, activation=\"sigmoid\", name=\"Amplitude_Prediction_Layer\")(combined_learning_layer)\n",
    "    \n",
    "    \n",
    "    model =  keras.Model(inputs=[label_input, song_input], outputs = predictive_layer, name=\"Song_Sequence_Predictor\", )\n",
    "    return model\n",
    "\n",
    "def pad_label_vector(label_vector: np.ndarray, vocab_size: int):\n",
    "    return np.pad(label_vector, (0, vocab_size - len(label_vector)))\n",
    "    \n",
    "\n",
    "sequence_length = 1_000\n",
    "\n",
    "model = build_model(sequence_length, 256, 99)\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.000001)\n",
    "loss = keras.losses.mean_squared_error\n",
    "model.compile(opt, loss, metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "example_song_directory = os.path.join(ROOT, \"Super Mario\")\n",
    "labels, title, song_data, sample_rate = load_song_data(example_song_directory)\n",
    "\n",
    "\n",
    "\n",
    "vectorized = pad_label_vector(vectorize_labels(labels, word_to_index), vocab_size)\n",
    "vectorized = tf.expand_dims(vectorized, 0)\n",
    "\n",
    "\n",
    "song_chunk =  tf.expand_dims(tf.expand_dims(normalize_song(song_data)[:sequence_length], 1), 0)\n",
    "\n",
    "\n",
    "print(\"Vectorized Labels:\")\n",
    "print(vectorized.shape)\n",
    "\n",
    "print(\"Song Data:\")\n",
    "print(song_chunk.shape)\n",
    "\n",
    "print(\"Prediction (:10): \")\n",
    "result = model([vectorized, song_chunk])[0][:10]\n",
    "print(result)\n",
    "\n",
    "print(\"Model Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a basic model together, we can transform data into inputs and outputs, and train the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 174/3610 [>.............................] - ETA: 7:32 - loss: nan - accuracy: 0.0885"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 29\u001b[0m\n\u001b[0;32m     24\u001b[0m labels, title, song_data, sample_rate \u001b[38;5;241m=\u001b[39m load_song_data(example_song_directory)\n\u001b[0;32m     27\u001b[0m labels, x, y \u001b[38;5;241m=\u001b[39m generate_song_datasets(labels, vocab_size, word_to_index, song_data, sequence_length)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def generate_song_datasets(labels: list[str], vocab_size:int, word_to_index: dict, song_data:np.ndarray, sequence_length: int):\n",
    "    # Vectorize the dataset into as many inputs as there are song sets.\n",
    "    # vectorized = tf.expand_dims(tf.expand_dims(vectorize_labels(labels, word_to_index), 1), 0)\n",
    "    \n",
    "    sequences = []\n",
    "    \n",
    "    for i in range(0, len(song_data), sequence_length):\n",
    "        sequence = song_data[i:i + sequence_length]\n",
    "        if len(sequence) < sequence_length:\n",
    "            sequence = np.pad(sequence, (0, sequence_length - len(sequence)))\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "    x = np.array(sequences[:-1])\n",
    "    y = np.array(sequences[1:])\n",
    "    \n",
    "    vectorized = pad_label_vector(vectorize_labels(labels, word_to_index), vocab_size)\n",
    "    vectorized_set = np.array([vectorized] * len(x))\n",
    "    \n",
    "    return vectorized_set, x, y\n",
    "    \n",
    "\n",
    "    \n",
    "example_song_directory = os.path.join(ROOT, \"Super Mario\")\n",
    "labels, title, song_data, sample_rate = load_song_data(example_song_directory)\n",
    "\n",
    "\n",
    "labels, x, y = generate_song_datasets(labels, vocab_size, word_to_index, song_data, sequence_length)\n",
    "\n",
    "model.fit([labels, x], y, epochs=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
